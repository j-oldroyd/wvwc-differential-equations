<?xml version="1.0" encoding="UTF-8" ?>

<chapter xml:id="systems-of-odes" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Systems of Ordinary Differential Equations</title>

  <shorttitle>Linear Systems</shorttitle>
  <section xml:id="section-systems-of-odes-as-models">
    <title>Systems of ODEs as models</title>

    <p>
      Interdependent quantities can often be represented mathematically by a system of equations.
      If we have information about the rates of change of these quantities, then we may be able to develop a model using a system of differential equations.
    </p>

    <definition xml:id="definition-first-order-system">
      <idx><h>first-order systems</h><h>definition</h></idx>
      <statement>
        <p>
          A <term>first order system</term> of ODEs is a system of differential equations involving some collection of functions and their first derivatives.
        </p>
      </statement>
    </definition>

    <p>
      We are still only dealing with ordinary differential equations which means that we will only ever have one independent variable.
      However, when dealing with systems of ODEs we will be working with several <em>dependent</em> variables.
    </p>

    <p>
      The systems of ODEs that we will consider will typically look like the following:
      <md>
        <mrow>x_{1}^\prime  \amp=  a_{11}x_{1} +a_{12}x_{2}+\dots+a_{1n}x_{n}</mrow>
        <mrow>x^\prime_{2}  \amp=  a_{21}x_{1} + a_{22}x_{2} + \dots + a_{2n}x_{2}</mrow>
        <mrow>\amp\vdots</mrow>
        <mrow>x^\prime_{n}  \amp=  a_{n1}x_{1} + a_{n2}x_{2} + \dots + a_{nn}x_{n}</mrow>
      </md>
      where <m>a_{ij}</m> are constants and <m>y_{i}</m> are functions of <m>t</m>.
    </p>

    <example xml:id="example-interconnected-tanks">
      <title>Modeling interconnected tanks</title>

      <statement>
        <p>
          Two brine tanks are set up as in <xref ref="figure-interconnected-tanks" text="type-global" />.
          Fresh water flows into the tank at a rate of <m>r_{1}</m>, well-mixed solution flows from Tank 1 to Tank 2 at a rate of <m>r_{2}</m> and well-mixed solution flows out of Tank 2 at a rate of <m>r_{3}</m>.
          Suppose that <m>r_{1}, r_{2}</m> and  <m>r_{3}</m> are <quantity><mag>5</mag><unit base="gallon"/><per base="minute"/></quantity>, the volume of solution in Tank 1 is <quantity><mag>10</mag><unit base="gallon"/></quantity> and the volume of solution in Tank 2 is <quantity><mag>7</mag><unit base="gallon" /></quantity>.
          Suppose Tank 1 has <quantity><mag>5</mag><unit base="pound"/></quantity> of salt at time <m>t=0</m> and Tank 2 has <quantity><mag>2</mag><unit base="pound"/></quantity> of salt at time <m>t=0</m>.
          Set up a first-order system that describes the amount of salt in each tank at time <m>t</m>.
        </p>
      </statement>

      <solution>
        <p>
          Let <m>x_{1}(t)</m> denote the amount of salt in Tank 1 at time <m>t</m>, and <m>x_{2}(t)</m> denote the amount of salt in Tank 2 at time <m>t</m>.
          Using the mixture ODE <m>\dv{x}{t} = r_{i}c_{i}-r_{o}\frac{x}{V(t)}</m> developed in <xref ref="section-first-order-linear-odes" text="type-global" />, we can write
          <md>
            <mrow>\dv{x_{1}}{t} \amp= 5\cdot0 - 5\frac{x_{1}}{10}</mrow>
            <mrow>\dv{x_{2}}{t} \amp= 5\frac{x_{1}}{10}-5\frac{x_{2}}{7}</mrow>
          </md>
          or just
          <md>
            <mrow>x^\prime_{1}  \amp=  -\frac{1}{2}x_{1}</mrow>
            <mrow>x^\prime_{2}  \amp=  \frac{1}{2}x_{1}-\frac{5}{7}x_{2},</mrow>
          </md>
          with initial conditions <m>x_{1}(0) = 5</m> and <m>x_{2}(0) = 2</m>.
        </p>
      </solution>
    </example>

    <figure xml:id="figure-interconnected-tanks">
      <caption>The two interconnected tanks from <xref ref="example-interconnected-tanks" text="type-global" />
      </caption>

      <image xml:id="image-interconnected-tanks" width="70%">
        <description>
          <p>
            A diagram representing a system of two interconnected tanks.
            Fresh water is flowing into the first tank.
            The well-mixed solution then flows from the first tank into the second tank.
            The well-mixed solution from the second tank then flows out of the system.
          </p>
        </description>
        <latex-image>
          \begin{tikzpicture}[scale=.7]
          % stolen shamelessly from stackexchange somebody CALL THE COPS
          % draw the tanks
          \draw (0,6)--(0,0)--(3,0)--(3,1)--(4,1)--(4,0)--(6,0)--(6,-1);
          \draw (7,-1)--(7,5)--(4,5)--(4,4)--(3,4)--(3,5)--(1,5)--(1,6);
          % fill Tank 1 with water (in the background)
          \begin{pgfonlayer}{background}
          \filldraw[blue!40] (0,4.5)--(3,4.5)--(3,4)% tank 1
          --(4,4)         % connection
          --(4,1)--(3,1)--(3,0)--(0,0) %back to tank 1
          -- cycle;
          \end{pgfonlayer}
          % fill Tank 2 with water (in the background)
          \begin{pgfonlayer}{background}
          \filldraw[blue!40] (4,3.5)--(7,3.5)--(7,-1)--(6,-1)--(6,0)--(4,0) % tank 2
          -- cycle;
          \end{pgfonlayer}
          % connection piece
          \filldraw[white,draw=white] (3,2)--(3,5)--(4,5)--(4,2)--cycle;
          \draw[color = black] (3,5)--(3,2)--(4,2)--(4,5);
          % add the rates
          \draw[-&gt;] (0.5,7)--(0.5,5)node[pos=0,anchor=south west]{$r_{1}$};
          \draw[-&gt;] (3,1.5)--(4,1.5)node[midway, yshift = .5cm]{$r_{2}$};
          \draw[-&gt;] (6.5,0)--(6.5,-2)node[pos=1,anchor=north]{$r_{3}$};
          \node at (1,1){Tank 1};
          \node at (6,1){Tank 2};
          \end{tikzpicture}
        </latex-image>
      </image>
    </figure>

    <p>
      To actually solve systems of ODEs, we'll use <em>matrices</em> to rewrite these systems as <em>matrix ODEs</em>.
    </p>

    <definition xml:id="definition-matrices-and-vectors">
      <title>Matrices and vectors</title>

      <idx><h>matrices</h><h>definition</h></idx>
      <idx><h>vectors</h><h>definition</h><see>matrices</see></idx>
      <statement>
        <p>
          An <m>m\times n</m> <term>matrix</term> is an array of <m>m</m> rows and <m>n</m> columns.
          <m>m\times1</m> matrices are called (<term>column</term>) <term>vectors</term>.
          Matrices are typically denoted with capital italic letters (such as <m>A</m>, <m>M</m>) and vectors are often denoted with lower case bold letters (such as <m>\vec{v},\vec{x})</m>.
          A <term>zero matrix</term> will be denoted using <m>\vec{0}</m>.
        </p>
      </statement>
    </definition>

    <p>
      As a brief example, let
      <me>
        A = \begin{bmatrix} 1\amp2\amp-1\\3\amp0\amp0\end{bmatrix}\quad\text{and}\quad \vec{y} = \begin{bmatrix} 1\\-1\\1 \end{bmatrix}.
      </me>
      Then <m>A</m> is a <m>2\times3</m> matrix and <m>\vec{y}</m> is a <m>3\times 1</m> vector.
    </p>

    <definition xml:id="definition-matrix-vector-product">
      <title>Matrix-vector product</title>

      <statement>
        <p>
          Let <m>A</m> be the <m>2\times 2</m> matrix
          <me>
            A = \begin{bmatrix} a_{11}\amp a_{12}\\a_{21}\amp a_{22} \end{bmatrix}
          </me>
          and let <m>\vec{v} = \begin{bmatrix} v_{1}\\v_{2} \end{bmatrix}</m>.
          Then their <term>product</term> <m>A\vec{v}</m> is the vector defined to be
          <me>
            A\vec{v} = \begin{bmatrix} a_{11}v_{1}+a_{12}v_{2}\\a_{21}v_{1}+a_{22}v_{2} \end{bmatrix}.
          </me>
          The <m>2\times 2</m> <term>identity matrix</term> is the matrix <m>I = \begin{bmatrix}1\amp0\\0\amp1\end{bmatrix}</m>.
          A <term>scalar</term> is just a constant.
          To multiply a scalar <m>c</m> with a matrix <m>A</m>, just multiply every element of <m>A</m> with <m>c</m>.
        </p>
      </statement>
    </definition>

    <p>
      If <m>A</m> is any <m>2\times2</m> matrix and <m>\vec{v}</m> and <m>2\times1</m> vector, then <m>AI=IA=A</m> and <m>I\vec{v} = \vec{v}</m>.
    </p>

    <example xml:id="example-systems-odes-matrix-vector-product">
      <title>Computing a matrix-vector product</title>

      <statement>
        <p>
          Let <m>A = \begin{bmatrix} 1\amp0\\-3\amp2 \end{bmatrix},\vec{v}_{1} = \begin{bmatrix}1\\1\end{bmatrix}</m> and <m>\vec{v}_{2} = \begin{bmatrix}0\\5\end{bmatrix}</m>.
          Compute <m>A\vec{v}_{1}</m> and <m>A\vec{v}_{2}</m>.
        </p>
      </statement>

      <solution>
        <p>
          By definition,
          <me>
            A\vec{v}_{1} = \begin{bmatrix}1\cdot1+0\cdot1\\-3\cdot1+2\cdot1\end{bmatrix} = \begin{bmatrix}1\\-1\end{bmatrix}\quad\text{and}\quad A\vec{v}_{2} = \begin{bmatrix}1\cdot0+0\cdot5\\-3\cdot0+2\cdot5\end{bmatrix} = \begin{bmatrix}0\\10\end{bmatrix}.
          </me>
        </p>
      </solution>
    </example>

    <p>
      In <xref ref="example-systems-odes-matrix-vector-product" text="type-global" />, notice that <m>A\vec{v}_{2} = 2\vec{v}_{2}</m>.
      This means that <m>A</m> didn't really do all that much to <m>\vec{v}_{2}</m> except to stretch it by a factor of <m>2</m>.
      Vectors with this property will turn out to be the key to solving our systems of ODEs.
    </p>

    <p>
      <em>Any</em> linear system can be written as an equivalent first-order system or matrix ODE.
    </p>

    <example xml:id="example-systems-odes-interconnected-spring-mass-system">
      <title>Interconnected spring-mass system</title>

      <statement>
        <p>
          Consider a spring mass system with two masses arranged as follows:
        </p>

        <image xml:id="image-systems-odes-interconnected-spring-mass-system" width="80%">
          <description>
            <p>
              A diagram representing two masses connected horizontally by springs.
              The first mass is connected to a wall by a spring.
              The first mass is also connected to the second mass by another spring with a possibly different spring constant.
            </p>
          </description>
          <latex-image>
                \begin{tikzpicture}
                % Stolen shamelessly from stackexchange.
                % This determines how the spring will look.
                \tikzstyle{spring}=[decorate,decoration={coil,pre length=0.3cm,post
                length=0.3cm,segment length=3,amplitude=1.5mm}]
                \tikzstyle{ground}=[fill,pattern=north east lines,draw=none,minimum
                width=0.75cm,minimum height=0.3cm]
                % This draws the blocks.
                \node[draw,outer sep=0pt,thick] (M1) [minimum width=1cm, minimum height=1cm] {$m_1$};
                \node[draw,outer sep=0pt,thick, right=of M1, xshift=2cm] (M2) [minimum width=1cm, minimum height=1cm] {$m_2$};
                % This draws the springs.
                \draw[spring] ($(M1.west) - (4,0)$) -- ($(M1.west)$) node [midway,yshift=.5cm] {$k_1$};
                \draw[spring] ($(M1.east)$) -- ($(M2.west)$) node [midway,yshift=.5cm] {$k_2$};
                % This draws the walls and floor.
                \draw[thick] ($(M1.south west) - (4,0)$) -- ($(M1.north west) + (-4,.5)$);
                \draw[thick] ($(M1.south west) - (4,0)$) -- ($(M1.south west) + (4,0)$);
                \draw[thick] ($(M2.south east)$) -- ($(M2.south east) + (4,0)$);
                \draw[thick] ($(M2.south east) + (4,0)$) -- ($(M2.north east) + (4,.5)$);
                % This draws the equilibrium positions.
                \draw[dashed] ($(M1.south west)-(2,.5)$) -- ($(M1.south west) - (2,-.5)$) node [below, yshift=-1cm,align=left] {\footnotesize Equilibrium\\ \footnotesize position};
                \draw[dashed] ($(M2.south west)-(2,.5)$) -- ($(M2.south west) - (2,-.5)$) node [below, yshift=-1cm,align=left] {\footnotesize Equilibrium\\ \footnotesize position}; 
                % This illustrates displacements.
                \draw [decorate,decoration={brace,amplitude=5pt,mirror},yshift=-2pt]
                ($(M1.south west)-(2,0)$) -- ($(M1.south west)$) node [black,midway,yshift=-10pt] {$x_1$};
                \draw [decorate,decoration={brace,amplitude=5pt,mirror},yshift=-2pt]
                ($(M2.south west)-(2,0)$) -- ($(M2.south west)$) node [black,midway,yshift=-10pt] {$x_2$};
                \end{tikzpicture}
          </latex-image>
        </image>

        <p>
          Determine a first-order system that the displacements <m>x_1</m> and <m>x_2</m> must satisfy.
        </p>
      </statement>

      <solution>
        <p>
          From <xref ref="section-spring-mass-models" text="type-global" /> we know how to model a spring-mass system with a single mass using <xref ref="theorem-hooke-s-law" text="custom">Hooke's law</xref> and Newton's Second Law.
          We will apply this same analysis to the displacements <m>x_1</m> and <m>x_2</m> individually.
        </p>

        <p>
          To begin, we will analyze the forces acting on the first mass.
          Here there are two forces to consider: the force caused by the motion of <m>m_1</m> and the force caused by the motion of <m>m_2</m>.
          Likewise, the second mass is also influenced by two forces.
          We arrange these in the following table:
        </p>

        <tabular top="major">
          <row bottom="minor">
            <cell>mass</cell>
            <cell>forces</cell>
          </row>

          <row>
            <cell><m>m_1</m></cell>
            <cell><m>-k_1x_1, -k_2x_1, k_2x_2</m></cell>
          </row>

          <row bottom="major">
            <cell><m>m_2</m></cell>
            <cell><m>k_2x_1, -k_2x_2</m></cell>
          </row>
        </tabular>

        <p>
          Now we can apply Newton's Second Law to get the <em>second</em>-order system
          <md>
            <mrow>m_1x_1'' \amp = -k_1x_1 - k_2x_1 + k_2x_2 </mrow>
            <mrow>m_2x_2'' \amp = k_2x_1 - k_2x_2 </mrow>
          </md>.
          At this point we can introduce new dependent variables <m>u_1, u_2, u_3</m> and <m>u_4</m> to get an equivalent first-order system.
        </p>

        <p>
          Although this type of system is new, the solutions behave as expected.
          In particular, both <m>x_1</m> and <m>x_2</m> display periodic motion as can be seen by the Sage example below.
        </p>
        <sage>
        <input>
                # Define our independent variable
                var('t')
                # Define the dependent variables as functions of t
                x1 = function('x_1')(t)
                x2 = function('x_2')(t)
                # System parameters
                m1, m2 = 1, 1
                k1, k2 = 4, 4
                # Define the equations in our system
                # If you wish to solve the corresponding first-order system,
                # you will need to specify four equations.
                de1 = m1*diff(x1, t, 2) == -(k1+k2)*x1 + k2*x2
                de2 = m2*diff(x1, t, 2) == k2*x1 - k2*x2
                # Display the (general) solution of this system
                # Note that the solution depends on initial conditions which
                # were NOT provided. In particular, D_0(x)(0) represents an
                # iniital condition of the form x'(0)
                show(desolve_system([de1, de2], [x1, x2]))
        </input>
        </sage>
      </solution>
    </example>

    <definition xml:id="definition-eigenvectors-and-eigenvalues">
      <title>Eigenvectors and eigenvalues</title>

      <idx><h>matrices</h><h>eigenvalues and eigenvectors</h></idx>
      <statement>
        <p>
          Let <m>A</m> be a matrix.
          A nonzero vector <m>\vec{v}</m> is an <term>eigenvector</term> of <m>A</m> if <m>A\vec{v} = \lambda\vec{v}</m> for some scalar <m>\lambda</m>.
          We call <m>\lambda</m> an <term>eigenvalue</term> of <m>A</m> corresponding to the eigenvector <m>\vec{v}</m>.
        </p>
      </statement>
    </definition>

    <example xml:id="example-eigenvalue-eigenvector">
      <title>Determining if a vector is an eigenvector</title>

      <statement>
        <p>
          Determine if <m>\vec{v} = \begin{bmatrix}-2\\1\end{bmatrix}</m> is an eigenvector of <m>A = \begin{bmatrix}1\amp4\\1\amp1\end{bmatrix}</m>.
        </p>
      </statement>

      <solution>
        <p>
          To do this, we just need to compute <m>A\vec{v}:</m>
          <me>
            A\vec{v} = \begin{bmatrix}1\amp4\\1\amp1\end{bmatrix}\begin{bmatrix}-2\\1\end{bmatrix} = \begin{bmatrix}2\\-1\end{bmatrix} = -\vec{v}
          </me>.
          So <m>\vec{v}</m> is an eigenvector of <m>A</m> with corresponding eigenvalue <m>\lambda=-1</m>.
        </p>
      </solution>
    </example>

    <p>
      Since we will be looking at systems of ODEs which involve functions, we will need to define vector-valued functions.
      These objects will represent the solutions of our systems.
    </p>

    <definition xml:id="definition-vector-valued-function">
      <title>Vector-valued functions</title>

      <idx><h>vectors</h><h>vector-valued functions</h></idx>
      <notation>
        <usage> <m>\vec{x}(t)</m> </usage>
        <description>
          a vector whose elements are functions
        </description>
      </notation>

      <statement>
        <p>
          A <term>vector-valued function</term> is a vector whose elements are functions.
          If each of the functions in a vector <m>\vec{x}</m> depends on the variable <m>t</m>, we often write <m>\vec{x}(t)</m> to denote this.
          The derivative of a vector-valued function <m>\vec{x}(t) = \begin{bmatrix}x_{1}(t)\\x_{2}(t)\end{bmatrix}</m> is the new vector-valued function <m>\vec{x}^\prime(t)=\begin{bmatrix}x^\prime_{1}(t)\\x^\prime_{2}(t)\end{bmatrix}</m>.
        </p>
      </statement>
    </definition>

    <p>
      We now have all of the tools we need to rewrite a first-order system as a matrix ODE.
      Let
      <md>
        <mrow>x^\prime \amp= a_{11}x+a_{12}y</mrow>
        <mrow>y^\prime \amp= a_{21}x+a_{22}y</mrow>
      </md>
      If <m>A = \begin{bmatrix}a_{11}\amp a_{12} \\ a_{21}\amp a_{22}\end{bmatrix}</m> and <m>\vec{x} = \begin{bmatrix}x\\y\end{bmatrix}</m>, then
      <me>
        A\vec{x} = \begin{bmatrix}x^\prime\\y^\prime\end{bmatrix} = \vec{x}^\prime
      </me>.
      In other words, we may rewrite the system as the matrix ODE
      <me>
        \vec{x}^\prime =A\vec{x}
      </me>.
    </p>

    <example xml:id="example-systems-odes-matrix-ode">
      <title>Writing a system as a matrix ODE</title>

      <statement>
        <p>
          Write the system
          <md>
            <mrow>x^\prime_{1}  \amp = -\frac{1}{2}x_{1}</mrow>
            <mrow>x^\prime_{2}  \amp = \frac{1}{2}x_{1}-\frac{5}{7}x_{2}</mrow>
          </md>
          as a matrix ODE.
        </p>
      </statement>

      <solution>
        <p>
          We need to find a matrix <m>A</m> and vector <m>\vec{x}</m> to let us rewrite this system.
          The matrix <m>A</m> is formed from the coefficients of <m>x_{1},x_{2}</m> on the right hand side of the system:
          <me>
            A = \begin{bmatrix}-\frac{1}{2}\amp 0\\\frac{1}{2}\amp -\frac{5}{7}\end{bmatrix}.
          </me>
          The vector <m>\vec{x}</m> is just made up of the dependent variables <m>x_{1},x_{2}</m>:
          <me>
            \vec{x} = \begin{bmatrix}x_{1}\\x_{2}\end{bmatrix}.
          </me>
          With these terms, the original system of ODEs is equivalent to the single matrix ODE
          <me>
            \vec{x}^\prime = A\vec{x}.
          </me>
        </p>
      </solution>
    </example>

    <example xml:id="example-systems-odes-matrix-ode-solution">
      <title>Solution of a matrix ODE</title>

      <statement>
        <p>
          Show that <m>e^{-t}\vec{x}_{0}</m> where <m>\vec{x}_{0} = \begin{bmatrix}-2\\1\end{bmatrix}</m> is a solution of the system
          <me>
            \vec{x}^\prime = \begin{bmatrix}1\amp 4\\1\amp 1\end{bmatrix}\vec{x}.
          </me>
        </p>
      </statement>

      <solution>
        <p>
          We'll check that <m>\vec{x}_{0}</m> is a solution of the matrix ODE just as we check solutions for normal ODEs: plug the potential solution into the ODE and check both sides.
          If we do so, we get
          <me>
            \dv{}{t}\brackets*{e^{-t}\vec{x}_{0}} = -e^{-t}\begin{bmatrix}-2\\1\end{bmatrix} = e^{-t}\begin{bmatrix}2\\-1\end{bmatrix}
          </me>
          and
          <me>
            \begin{bmatrix}1\amp 4\\1\amp 1\end{bmatrix}e^{-t}\vec{x}_{0} = e^{-t}\begin{bmatrix}1\amp 4\\1\amp 1\end{bmatrix}\begin{bmatrix}-2\\1\end{bmatrix} = e^{-t}\begin{bmatrix}2\\-1\end{bmatrix}
          </me>.
          Since these expressions match, this means that <m>e^{-t}\vec{x}_{0}</m> is a solution of the ODE.
        </p>
      </solution>
    </example>

    <p>
      One thing to note about the previous example is that <m>\begin{bmatrix}-2\\1\end{bmatrix}</m> was an eigenvector of <m>\begin{bmatrix}1\amp 4\\1\amp 1\end{bmatrix}</m> with corresponding eigenvalue <m>\lambda=-1</m>.
      See <xref ref="example-eigenvalue-eigenvector" text="type-global" />.
      This suggests that solutions of the matrix ODE <m>\vec{x}^\prime = A\vec{x}</m> take the form <m>\vec{x} = e^{\lambda t}\vec{x}_{0}</m>, where <m>\lambda</m> is an eigenvalue of <m>A</m> with corresponding eigenvector <m>\vec{x}_{0}</m>.
      One last concept we need is that of linear independence of vectors.
    </p>

    <definition xml:id="definition-linear-independence-of-vectors">
      <title>Linear independence of vectors</title>

      <idx><h>linear independence</h><h>vectors</h></idx>
      <statement>
        <p>
          Let <m>\vec{x}_{1},\dots,\vec{x}_{n}</m> denote a collection of vectors.
          We say that the vectors are <term>linearly independent</term> if the equality
          <me>
            \sum_{i=1}^{n}c_{i}\vec{x}_{i} = \vec{0}
          </me>
          is possible if and only if <m>c_{1}=\dots=c_{n}=0</m>.
          Otherwise, we say that the vectors are <term>linearly dependent</term>.
        </p>
      </statement>
    </definition>

    <p>
      Just as before, our primary tool for showing if a collection is linearly independent is the Wronskian.
    </p>

    <definition xml:id="definition-wronskian-of-vectors">
      <idx><h>Wronskian</h><h>vectors</h></idx>
      <notation>
        <usage> <m>W(\vec{x_1}, \vec{x_2}, \ldots, \vec{x_n})</m> </usage>
        <description>
          the Wronskian of <m>n</m> vectors
        </description>
      </notation>

      <statement>
        <p>
          The <term>Wronskian</term> of <m>\vec{x}_{1},\dots,\vec{x}_{n}</m> is the number <m>W(\vec{x}_{1},\dots,\vec{x}_{n})</m> defined by
          <me>
            W(\vec{x}_{1},\dots,\vec{x}_{n}) = \begin{vmatrix}\vec{x}_{1}  \amp  \dots   \amp  \vec{x}_{n}\end{vmatrix}.
          </me>
          The vectors <m>\vec{x}_{1},\dots,\vec{x}_{n}</m> are linearly independent if and only if their Wronskian is nonzero.
        </p>
      </statement>
    </definition>
  </section>

  <section xml:id="section-constant-coefficient-systems-and-the-phase-plane">
    <title>Constant coefficient systems</title>

    <introduction>
      <p>
        The content in this section represents a higher-dimensional analog of the content in <xref ref="section-second-order-linear-odes" text="type-global" />.
      </p>
    </introduction>


    <subsection xml:id="subsection-matrix-odes-constant-coefficients">
      <title>Solutions of <m>\vec{x}^\prime = A\vec{x}</m></title>

      <p>
        A system of ODEs involving only constant coefficients can be rewritten as a matrix ODE of the form <m>\vec{x}^\prime = A\vec{x}</m> where <m>A</m> is a constant matrix.
        Such a system can be solved using exponentials.
      </p>

      <theorem xml:id="theorem-solutions-of-matrix-odes-constant-coefficients">
        <title>Solutions of systems</title>

        <statement>
          <p>
            Let <m>A</m> be an <m>n\times n</m> constant matrix, and suppose that <m>A</m> has <m>n</m> linearly independent eigenvectors <m>\vec{x}_{1},\dots,\vec{x}_{n}</m> with corresponding eigenvalues <m>\lambda_{1},\dots,\lambda_{1}</m>.
            Then the general solution of <m>\vec{x}^\prime=A\vec{x}</m> is given by
            <me>
              \vec{x} = \sum_{i=1}^{n}c_{i}e^{\lambda_{i}t}\vec{x}_{i}.
            </me>
          </p>
        </statement>
      </theorem>

      <example>
        <statement>
          <p>
            Find the general solution of the system
            <md>
              <mrow>x_{1}^\prime  \amp = x_{1}-\frac{1}{2}x_{2}-\frac{1}{2}x_{3}</mrow>
              <mrow>x^\prime_{2}  \amp =  -\frac{1}{2}x_{1}+x_{2}-\frac{1}{2}x_{3}</mrow>
              <mrow>x^\prime_{3}  \amp =  -\frac{1}{2}x_{1}-\frac{1}{2}x_{2}+x_{3}</mrow>
            </md>
            given that
            <me>
              \vec{x}_{1} = \begin{bmatrix}1\\1\\1\end{bmatrix},\vec{x}_{2} = \begin{bmatrix}-1\\1\\0\end{bmatrix}\quad\text{and}\quad\vec{x}_{3} = \begin{bmatrix}-\frac{1}{2}\\-\frac{1}{2}\\1\end{bmatrix}
            </me>
            are eigenvectors of the matrix
            <me>
              G = \begin{bmatrix}1 \amp  -\frac{1}{2}  \amp  -\frac{1}{2}\\-\frac{1}{2}  \amp  1 \amp  -\frac{1}{2} \\ -\frac{1}{2}  \amp  -\frac{1}{2}  \amp    1\end{bmatrix}
            </me>
            with corresponding eigenvalues <m>\lambda_{1} = 0,\lambda_{2} = \lambda_{3} = \frac{3}{2}</m>.
          </p>
        </statement>

        <solution>
          <p>
            First, note that the system we need to solve is equivalent to the matrix ODE <m>\vec{x}^\prime = G\vec{x}</m>.
            If we can show that <m>\vec{x}_{1},\vec{x}_{2},\vec{x}_{3}</m> are linearly independent, then we can use <xref ref="theorem-solutions-of-matrix-odes-constant-coefficients" text="type-global" /> to find the general solution of the system.
            So we'll compute their Wronskian:
            <md>
              <mrow>W(\vec{x}_{1},\vec{x}_{2},\vec{x}_{3}) \amp = \begin{vmatrix} 1  \amp  -1  \amp  -\frac{1}{2} \\ 1 \amp  1 \amp  -\frac{1}{2} \\ 1 \amp  0 \amp  1\end{vmatrix}</mrow>
              <mrow>\amp = 1+\frac{3}{2}+\frac{1}{2}</mrow>
              <mrow>\amp = 3</mrow>
            </md>.
          </p>

          <p>
            Since the Wronskian is nonzero, these eigenvectors are linearly independent.
            Therefore the general solution of the system is given by
            <md>
              <mrow>\vec{x} \amp = c_{1}e^{0t}\vec{x}_{1}+c_{2}e^{3t/2}\vec{x}_{2}+c_{3}e^{3t/2}\vec{x}_{3}</mrow>
              <mrow>\amp = \begin{bmatrix}c_{1}-c_{2}e^{3t/2}-\frac{1}{2}c_{3}e^{3t/2} \\ c_{1}+c_{2}e^{3t/2}-\frac{1}{2}c_{3}e^{3t/2} \\ c_{1}+c_{3}e^{3t/2}\end{bmatrix}</mrow>
            </md>
            or just
            <md>
              <mrow>x_{1} \amp = c_{1}-\parens{c_{2}-\frac{1}{2}c_{3}}e^{3t/2}</mrow>
              <mrow>x_{2} \amp = c_{1}+\parens{c_{2}-\frac{1}{2}c_{3}}e^{3t/2}</mrow>
              <mrow>x_{3} \amp = c_{1}+c_{3}e^{3t/2}</mrow>
            </md>
          </p>
        </solution>
      </example>
    </subsection>


    <subsection xml:id="subsection-finding-eigenvalues-and-eigenvectors">
      <title>Finding eigenvalues and eigenvectors</title>

      <p>
        <xref ref="theorem-solutions-of-matrix-odes-constant-coefficients" text="type-global" /> shows that solving systems of first-order ODEs comes down to finding eigenvalues and eigenvectors of the corresponding matrix ODE. So it's important for us to know how to find these.
      </p>

      <p>
        Let <m>A</m> be an <m>n\times n</m> matrix and suppose that <m>\vec{v}</m> is an eigenvector with corresponding eigenvalue <m>\lambda</m>.
        Then
        <me>
          A\vec{v} = \lambda\vec{v}
        </me>.
        We can rearrange this to get
        <me>
          A\vec{v}-\lambda\vec{v} = (A-\lambda I)\vec{v} = \vec{0}
        </me>
        where <m>I</m> is the identity matrix.
        Since <m>\vec{v}\neq\vec{0}</m> (since it's an eigenvector!), linear algebra tells us that <m>\det(A-\lambda I) = 0</m>.
        This gives us the following definition and theorem.
      </p>

      <definition xml:id="definition-characteristic-equation">
        <statement>
          <p>
            <m>\det(A-\lambda I)=0</m> is called the <term>characteristic equation</term> of the matrix <m>A</m>.
          </p>
        </statement>
      </definition>

      <theorem xml:id="theorem-theorem-eigenvalues-from-characteristic-equation">
        <title>Eigenvalues and the characteristic equation</title>

        <statement>
          <p>
            The eigenvalues of a square matrix <m>A</m> are the solutions of the equation <m>\det(A-\lambda I) = 0</m>.
          </p>
        </statement>
      </theorem>

      <example xml:id="example-system-odes-finding-eigenvalues-2x2">
        <title>Finding eigenvalues of a <m>2\times2</m> matrix</title>

        <statement>
          <p>
            Find the eigenvalues of the matrix <m>A = \begin{bmatrix}1\amp 4\\1\amp 1\end{bmatrix}</m>.
          </p>
        </statement>

        <solution>
          <p>
            First, we need to set up the characteristic equation of <m>A</m>.
            Since
            <me>
              A-\lambda I = \begin{bmatrix}1-\lambda \amp  4 \\ 1 \amp  1-\lambda\end{bmatrix}
            </me>,
            we get
            <me>
              \det(A-\lambda I) = (1-\lambda)^{2} - 4 = \lambda^{2}-2\lambda+3
            </me>
            so the characteristic equation of <m>A</m> is
            <me>
              \lambda^{2}-2\lambda+3 = 0
            </me>
            which has solutions <m>\lambda_{1} = -1,\lambda_{2} = 3</m>.
            So the eigenvalues of <m>A</m> are <m>-1,3</m>.
          </p>
        </solution>
      </example>

      <p>
        These computations are easily verified by Sage or MATLAB/Octave.
        Sage can provide exact answers but the code is somewhat cumbersome.
        MATLAB on the other hand is designed for performing matrix computations and therefore its code for finding eigenvalues is simpler.
        We only need to use the <c>eig</c> command:
      </p>
      <sage language="octave">
      <input>
          % Define the matrix
          A = [1, 1; 1, 4];
          % Compute the eigenvalues of A
          eig(A)
      </input>
      <output>
          ans =
              3.0000
             -1.0000
      </output>
      </sage>

      <p>
        A useful fact to remember is that the eigenvalues of a <q>triangular</q> matrix are just the diagonal entries.
      </p>

      <example xml:id="system-odes-eigenvalues-triangular-matrix">
        <title>Finding the eigenvalues of a triangular matrix</title>

        <statement>
          <p>
            Let
            <me>
              A = \begin{bmatrix}1 \amp  3 \amp  -4 \amp  5 \\ 0 \amp  3 \amp  -2 \amp  -2 \\ 0 \amp  0 \amp  1 \amp  10^{50\pi-300} \\ 0 \amp  0 \amp  0 \amp  0\end{bmatrix}
            </me>.
            Find the eigenvalues of <m>A</m>.
          </p>
        </statement>

        <solution>
          <p>
            <m>A</m> is a triangular matrix since everything below the main diagonal is <m>0</m>. Therefore the eigenvalues of <m>A</m> are <m>1,3,1,0</m>.
          </p>
        </solution>
      </example>

      <p>
        Once we have the eigenvalues of a matrix, we can find their corresponding eigenvectors.
      </p>

      <example xml:id="example-system-odes-finding-eigenvectors-2x2">
        <title>Finding eigenvectors for a <m>2\times2</m> matrix</title>

        <statement>
          <p>
            Find eigenvectors of <m>A = \begin{bmatrix}1 \amp  4 \\ 1 \amp  1\end{bmatrix}</m> corresponding to the eigenvalues <m>\lambda_{1} = -1</m> and <m>\lambda_{2} = 3</m>.
          </p>
        </statement>

        <solution>
          <p>
            Suppose that <m>\vec{v} = \begin{bmatrix} v_{1} \\ v_{2} \end{bmatrix}</m> is an eigenvector corresponding to <m>\lambda</m>.
            Then we know that
            <me>
              \begin{bmatrix}1 \amp  4 \\ 1 \amp  1\end{bmatrix}\vec{v} = \lambda\vec{v} \Rightarrow \begin{bmatrix}v_{1}+4v_{2} \\ v_{1} + v_{2}\end{bmatrix} = \begin{bmatrix} \lambda v_{1} \\ \lambda v_{2} \end{bmatrix}
            </me>.
            This tells us that if <m>\vec{v} = \begin{bmatrix}v_{1} \\ v_{2} \end{bmatrix}</m> is an eigenvector for <m>\lambda</m>, then its entries need to satisfy
            <md>
              <mrow>v_{1}+4v_{2}\amp =\lambda v_{1}</mrow>
              <mrow>v_{1}+v_{2} \amp = \lambda v_{2}</mrow>
            </md>
            which boils down to
            <md>
              <mrow>(1-\lambda)v_{1}+4v_{2} \amp = 0</mrow>
              <mrow>v_{1} + (1-\lambda)v_{2} \amp = 0.</mrow>
            </md>
          </p>

          <p>
            Now set <m>\lambda = -1</m> to get the system
            <md>
              <mrow>2v_{1} + 4v_{2} \amp = 0</mrow>
              <mrow>v_{1} + 2v_{2} \amp = 0</mrow>
            </md>
            and so <m>v_{1} = -2v_{2}</m>.
            We don't really care about what the entries of <m>\vec{v}</m> look like so long as <m>\vec{v}</m> is an eigenvector, so we can pick <m>v_{1},v_{2}</m> however we want, just so long as they satisfy this relation (and are not both <m>0</m>!).
            So pick <m>v_{2} = 1</m>, which forces <m>v_{1} = -2</m>.
            Then
            <me>
              \vec{v} = \begin{bmatrix}-2\\1\end{bmatrix}
            </me>
            is an eigenvector of <m>A</m> corresponding to the eigenvalue <m>\lambda_{1} = -1</m>.
          </p>

          <p>
            To find an eigenvector for <m>\lambda_{2} = 3</m> we just set <m>\lambda  = 3</m> and run through the same process:
            <md>
              <mrow>-2v_{1}+4v_{2} \amp = 0</mrow>
              <mrow>v_{1} - 2v_{2} \amp = 0</mrow>
            </md>
            The second equation simplifies to <m>v_{1} = 2v_{2}</m>, so one eigenvector for <m>\lambda_{2}</m> is
            <me>
              \vec{v} = \begin{bmatrix}2 \\ 1\end{bmatrix}.
            </me>
          </p>
        </solution>
      </example>

      <p>
        Of course, all of this can be done in Sage or MATLAB/Octave as well.
        If we use MATLAB/Octave, then the <c>eig</c> command once again does the heavy lifting for us.
        Each column of the matrix <m>U</m> produced below is an eigenvector of <m>A</m>.
      </p>
      <sage language="octave">
      <input>
          # Define A
          A = [1, 4; 1, 1];
          # Compute eigenvectors
          [U, V] = eig(A)
      </input>
      <output>
          U =
              0.8944   -0.8944
              0.4472    0.4472
          V =
              3.0000         0
                   0   -1.0000
      </output>
      </sage>

      <p>
        Looking forward to <xref ref="theorem-linear-independence-distinct-eigenvalues" text="type-global" />, note that the eigenvectors we found in <xref ref="example-system-odes-finding-eigenvectors-2x2" text="type-global" /> are linearly indepednent.
        This can be verified by computing the Wronskian as done using Sage below:
      </p>
      <aside>
      <p>
        You may have noticed that the matrix constructed in the Sage cell here is actually <q>flipped</q>: the eigenvectors are appearing as the rows instead of the columns.
        It turns out that this causes no problems for us since turning rows into columns (or columns into rows) has no affect on the determinant.
        Therefore the Wronskian is unchanged.
      </p>
      </aside>
      <sage>
      <input>
          # Define our vectors
          v1 = vector([-2, 1])
          v2 = vector([2, 1])
          # Define our matrix
          M = matrix([v1, v2])
          # Compute the determinant, i.e., the Wronskian
          M.det()
      </input>
      <output>
          -4
      </output>
      </sage>
    </subsection>


    <subsection xml:id="subsection-solving-matrix-odes">
      <title>Solving matrix odes</title>

      <p>
        We now have the tools we need to begin solving matrix ODEs.
        Recall that if <m>A</m> is an <m>n\times n</m> matrix with constant entries, and if <m>\vec{x}_{1},\vec{x}_{2},\ldots,\vec{x}_{n}</m> are <m>n</m> linearly independent solutions of the matrix ODE <m>\vec{x}^\prime=A\vec{x}</m>, then the general solution of the matrix ODE is
        <me>
          \vec{x} = \sum_{k=1}^{n}c_{k}\vec{x}_{k}
        </me>.
        Furthermore, if <m>\lambda</m> is an eigenvalue of <m>A</m> with eigenvector <m>\vec{v}</m>, then <m>e^{\lambda t}\vec{v}</m> is a solution of <m>\vec{x}^\prime=A\vec{x}</m>.
        So solving the matrix ODE <m>\vec{x}^\prime=A\vec{x}</m> requires finding enough eigenvectors and eigenvalues.
        A useful theorem is the following:
      </p>

      <theorem xml:id="theorem-linear-independence-distinct-eigenvalues">
        <title>Distinct eigenvalues and linear independence</title>

        <statement>
          <p>
            Let <m>A</m> be an <m>n\times n</m> matrix with constant entries.
            If the eigenvalues <m>\lambda_{1},\ldots,\lambda_{n}</m> of <m>A</m> are distinct (that is, none are repeated) then eigenvectors associated with different eigenvalues are linearly independent.
            That is, if <m>\vec{v}_{i}</m> is an eigenvector corresponding to <m>\lambda_{i}</m> then the eigenvectors <m>\vec{v}_{1},\ldots,\vec{v}_{n}</m> are linearly independent.
          </p>
        </statement>
      </theorem>

      <example xml:id="example-systems-ode-solving-2x2-matrix-ode">
        <title>Solving a matrix ODE</title>

        <statement>
          <p>
            Solve the matrix ODE given by <m>\vec{x}^\prime = A\vec{x}</m> where
            <me>
              A = \begin{bmatrix}1\amp 4\\1\amp 1\end{bmatrix}
            </me>.
          </p>
        </statement>

        <solution>
          <p>
            We already have everything we need.
            We know that the eigenvalues of <m>A</m> are <m>\lambda_{1}=-1</m> and <m>\lambda_{2}=3</m> from <xref ref="example-system-odes-finding-eigenvalues-2x2" text="type-global"/>, and likewise some corresponding eigenvectors are
            <me>
              \vec{v}_{1} = \begin{bmatrix}-2\\1\end{bmatrix}\qq{and} \vec{v}_{2} = \begin{bmatrix}2\\1\end{bmatrix}
            </me>
            thanks to <xref ref="example-system-odes-finding-eigenvectors-2x2" text="type-global" />.
            Since the eigenvalues are distinct it follows that these eigenvectors are linearly independent (we could also check this using the Wronskian).
            We can therefore build two linearly independent solutions to the matrix ODE:
            <me>
              \vec{x}_{1} = e^{\lambda_{1}t}\vec{v}_{1} = e^{-t}\begin{bmatrix}-2\\1\end{bmatrix}\qq{and} \vec{x}_{2} = e^{\lambda_{2}t}\vec{v}_{2} = e^{3t}\begin{bmatrix}2\\1\end{bmatrix}
            </me>.
            So the general solution of the matrix ODE is
            <me>
              \vec{x} = c_{1}\vec{x}_{1} + c_{2}\vec{x}_{2} = c_{1}e^{-t}\begin{bmatrix}-2\\1\end{bmatrix} + c_{2}e^{3t}\begin{bmatrix}2\\1\end{bmatrix}
            </me>.
          </p>

          <p>
            Note that the choice of eigenvector <em>doesn't matter</em>.
            We only need to find enough linearly independent eigenvectors for each distinct eigenvalue.
          </p>
        </solution>
      </example>

      <example xml:id="example-systems-odes-solving-system-two-equations">
        <title>Solving a first-order system with two equations</title>

        <statement>
          <p>
            Solve the first-order system given by
            <md>
              <mrow>x_{1}^\prime \amp = x_{1} - 5x_{2}</mrow>
              <mrow>x_{2}^\prime \amp = x_{1} - x_{2}</mrow>
            </md>
            where <m>x_{1}</m> and <m>x_{2}</m> are functions of <m>t</m>.
          </p>
        </statement>

        <solution>
          <p>
            First, note that this system is equivalent to the matrix ODE <m>\vec{x}^\prime = A\vec{x}</m> where
            <me>
              \vec{x} = \begin{bmatrix}x_{1} \\ x_{2}\end{bmatrix}\qq{and} A = \begin{bmatrix}1 \amp  -5 \\ 1 \amp  -1\end{bmatrix}
            </me>.
            To solve this system we need to find the eigenvalues and eigenvectors of <m>A</m>, and then use these to build our general solution.
            <ol>
              <li>
                <p>
                  Find the eigenvalues.
                </p>

                <p>
                  We find the eigenvalues of <m>A</m> by solving the characteristic equation <m>\det(A - \lambda I) = 0</m> for <m>\lambda</m>.
                  Since <m>\det(A - \lambda I) = \lambda^{2}+4</m>, we see that the eigenvalues of <m>A</m> are <m>\lambda_{1} = -2i</m> and <m>\lambda_{2} = 2i</m>.
                  The fact that these eigenvalues are complex is <em>not</em> a problem.
                  They're still distinct, so our method will work.
                </p>
              </li>

              <li>
                <p>
                  Find corresponding eigenvectors.
                </p>

                <p>
                  Set <m>\vec{v} = \begin{bmatrix}v_{1} \\ v_{2}\end{bmatrix}</m>.
                  Then <m>A\vec{v} = \lambda\vec{v}</m> implies that
                  <md>
                    <mrow>v_{1} - 5v_{2}  \amp =  \lambda v_{1}</mrow>
                    <mrow>v_{1} -v_{2}  \amp =  \lambda v_{2}</mrow>
                  </md>
                  or just
                  <md>
                    <mrow>(1-\lambda)v_{1} - 5v_{2} \amp =0</mrow>
                    <mrow>v_{1} - (1+\lambda)v_{2} \amp = 0.</mrow>
                  </md>
                  Setting <m>\lambda=-2i</m> in the second equation gives <m>v_{1} = (1-2i)v_{2}</m>, so an eigenvector of <m>A</m> corresponding to <m>\lambda_{1} = -2i</m> is
                  <me>
                    \vec{v} = \begin{bmatrix}1-2i \\ 1\end{bmatrix}
                  </me>.
                  Similarly, an eigenvector corresponding to <m>\lambda_{2}=2i</m> is
                  <me>
                    \vec{v}_{2} = \begin{bmatrix}1+2i\\1\end{bmatrix}
                  </me>.
                </p>
              </li>

              <li>
                <p>
                  Find the general solution.
                </p>

                <p>
                  At this step it is easy to construct the solution of the matrix ODE.
                  It's just
                  <me>
                    \vec{x} = c_{1}e^{\lambda_{1}t}\vec{v}_{1} + c_{2}e^{\lambda_{2}t}\vec{v}_{2} = \begin{bmatrix}c_{1}e^{-2it}(1-2i)+c_{2}e^{2it}(1+2i) \\ c_{1}e^{-2it}+c_{2}e^{2it}\end{bmatrix}.
                  </me>
                </p>
              </li>
            </ol>
          </p>
        </solution>
      </example>

      <example xml:id="example-systems-odes-3x3-system">
        <title>Solving a system of three differential equations</title>

        <statement>
          <p>
            Solve the first-order system
            <md>
              <mrow>\dv{x_{1}}{t} \amp = 3x_{1}+x_{3}</mrow>
              <mrow>\dv{x_{2}}{t} \amp = 9x_{1}-x_{2}+2x_{3}</mrow>
              <mrow>\dv{x_{3}}{t} \amp = -9x_{1} + 4x_{2} - x_{3}</mrow>
            </md>.
          </p>
        </statement>

        <solution>
          <p>
            As long as this system has distinct eigenvalues the above method will work.
            Once again we rewrite the system as a matrix ODE; in this case, the matrix ODE we must solve is
            <me>
              \vec{x}^\prime = \begin{bmatrix}3 \amp  0 \amp  1 \\ 9 \amp  -1 \amp  2 \\ -9 \amp  4 \amp  -1\end{bmatrix}\vec{x} = A\vec{x}
            </me>.
          </p>

          <p>
            To find the eigenvalues we must solve the characteristic equation <m>\det(A-\lambda I)=0</m>.
            However, we can also use Sage to perform this task.
          </p>
          <aside>
          <p>
            We could also use MATLAB/Octave, but the resulting eigenvectors wouldn't look as nice as the output provided by Sage.
            This is because MATLAB's <c>eig</c> command produces <term>normalized</term> output which often involves dividing entries by square roots.
          </p>
          </aside>
          <sage>
          <input>
              # Define our matrix
              M = matrix([ [3, 0, 1],
              [9, -1, 2],
              [-9, 4, -1]] )
              # Finds eigenvectors, corresponding eigenvalues and "algebraic multiplicty".
              M.eigenvectors_right()
          </input>
          <output>
              [(3,
                [
                (1, 9/4, 0)
                ],
                1),
               (-1 - 1*I, [(1, 2 + 1*I, -4 - 1*I)], 1),
               (-1 + 1*I, [(1, 2 - 1*I, -4 + 1*I)], 1)]
          </output>
          </sage>

          <p>
            This produces a list containing the eigenvalues of <m>A</m> as well as the corresponding eigenvectors.
            So we see that the eigenvalues are given by
            <me>
              \lambda_{1} = 3, \quad\lambda_{2} = -1 - i\quad\text{ and }\quad\lambda_{3} = -1 + i
            </me>,
            while the corresponding eigenvectors are given by
            <me>
              \vec{v}_{1} = \begin{bmatrix}1 \\ \frac{9}{4} \\ 0\end{bmatrix}, \quad\vec{v}_{2} = \begin{bmatrix} 1 \\ 2 + i \\ -4 - i \end{bmatrix}\quad\text{and}\vec{v}_{3} = \begin{bmatrix} 1 \\ 2 - i \\ -4 + i \end{bmatrix}
            </me>.
          </p>

          <p>
            We now have everything we need for the general solution of the matrix ODE.
            It's just
            <me>
              \vec{x} = c_{1}e^{3t}\begin{bmatrix}1 \\ \frac{9}{4} \\ 0\end{bmatrix} + c_{2}e^{(-1 - i)t}\begin{bmatrix} 1 \\ 2 + i \\ -4 - i \end{bmatrix} + c_{3}e^{(-1 + i)t}\begin{bmatrix} 1 \\ 2 - i \\ -4 + i \end{bmatrix}
            </me>.
          </p>
        </solution>
      </example>
    </subsection>


    <subsection xml:id="subsection-applications-of-matrix-odes">
      <title>Applications of matrix ODEs</title>

      <p>
        Now we use matrix ODEs to model physical systems.
        The methods we've developed for solving matrix ODEs will then let us come up with descriptions for such systems.
        Recall that we introduced systems of ODEs (and then matrix ODEs) to model quantities that depended on time (an independent variable) and each other (dependent variables).
        The physical systems we will consider will be ones where the quantities of interest depend on each other in some way.
      </p>

      <example xml:id="example-system-odes-brine-tanks-model-solution">
        <title>Determining salt concentration in connected tank system</title>

        <statement>
          <p>
            Two brine tanks are set up as in <xref ref="figure-interconnected-tanks" text="type-global" />.
            Fresh water flows into the tank at a rate of <m>r_{1}</m>, well-mixed solution flows from Tank 1 to Tank 2 at a rate of <m>r_{2}</m> and well-mixed solution flows out of Tank 2 at a rate of <m>r_{3}</m>.
            Suppose that <m>r_{1}, r_{2}</m> and  <m>r_{3}</m> are <quantity><mag>5</mag><unit base="gallon"/><per base="minute"/></quantity>, the volume of solution in Tank 1 is <quantity><mag>10</mag><unit base="gallon"/></quantity> and the volume of solution in Tank 2 is <quantity><mag>7</mag><unit base="gallon" /></quantity>.
            Suppose Tank 1 has <quantity><mag>5</mag><unit base="pound"/></quantity> of salt at time <m>t=0</m> and Tank 2 has <quantity><mag>2</mag><unit base="pound"/></quantity> of salt at time <m>t=0</m>.
            How much salt is in each tank at time <m>t</m>?
          </p>
        </statement>

        <solution>
          <p>
            To start, let <m>x_{1}(t)</m> denote the amount of salt in Tank 1 at time <m>t</m> and <m>x_{2}(t)</m> denote the amount of salt in Tank 2 at time <m>t</m>, where <m>t</m> is in minutes.
            Then from Section 4.1, we know that
            <md>
              <mrow>x^\prime_{1} \amp = -\frac{1}{2}x_{1}</mrow>
              <mrow>x^\prime_{2} \amp = \frac{1}{2}x_{1}-\frac{5}{7}x_{2}</mrow>
            </md>.
            If we set
            <me>
              \vec{x} = \begin{bmatrix} x_{1} \\ x_{2} \end{bmatrix} \qq{and} A = \begin{bmatrix}-\frac{1}{2} \amp  0 \\ \frac{1}{2} \amp  -\frac{5}{7}\end{bmatrix}
            </me>
            then this system is equivalent to the matrix ODE <m>\vec{x}^\prime = A\vec{x}</m>.
          </p>

          <p>
            To solve this, we find the eigenvalues and corresponding eigenvectors.
            To find the eigenvalues, we could solve the characteristic equation <m>\det(A-\lambda I) = 0</m> or use technology, but it's easier to note that <m>A</m> is a triangular matrix.
            So the eigenvalues are just <m>\lambda_{1} = -\frac{1}{2},\lambda_{2} = -\frac{5}{7}</m>.
          </p>

          <p>
            Now we find corresponding eigenvectors.
            So let
            <me>
              \vec{v} = \begin{bmatrix}v_{1} \\ v_{2}\end{bmatrix}
            </me>.
            If <m>\vec{v}</m> is an eigenvector for <m>\lambda</m>, then we know <m>A\vec{v} = \lambda\vec{v}</m>, which gives the system
            <md>
              <mrow>(-\frac{1}{2}-\lambda)v_{1} \amp = 0</mrow>
              <mrow>\frac{1}{2}v_{1} + (-\frac{5}{7}-\lambda)v_{2} \amp = 0</mrow>
            </md>.
            If we set <m>\lambda=-\frac{1}{2}</m>, then we just get <m>v_{1} = \frac{3}{14}v_{2}</m>.
            So an eigenvector corresponding to <m>\lambda_{1} = -\frac{1}{2}</m> is
            <me>
              \vec{v}_{1} = \begin{bmatrix}3\\14\end{bmatrix}
            </me>.
          </p>

          <p>
            Similarly, if we set <m>\lambda=-\frac{5}{7}</m> we get <m>v_{1} = 0</m>, but no restrictions on <m>v_{2}</m>.
            So an eigenvector corresponding to <m>\lambda_{2} = -\frac{5}{7}</m> is
            <me>
              \vec{v}_{2} = \begin{bmatrix}0\\1\end{bmatrix}
            </me>.
          </p>

          <p>
            We can now write down the general solution of the matrix ODE:
            <me>
              \vec{x} = c_{1}e^{-\frac{5t}{7}}\begin{bmatrix}0\\1\end{bmatrix} + c_{2}e^{-\frac{t}{2}}\begin{bmatrix}3\\14\end{bmatrix} = \begin{bmatrix}3c_{2}e^{-\frac{t}{2}} \\ c_{1}e^{-\frac{5t}{7}}+14c_{2}e^{-\frac{t}{2}}\end{bmatrix}
            </me>.
            But we're not done yet, since we have the initial conditions <m>x_{1}(0) = 5</m> and <m>x_{2}(0) = 2</m>, or in terms of our matrix ODE
            <me>
              \vec{x}(0) = \begin{bmatrix}5\\2\end{bmatrix}
            </me>.
            We can use this to find <m>c_{1}</m> and <m>c_{2}</m>.
            If we set <m>t=0</m> then we get
            <me>
              \begin{bmatrix}3c_{2} \\ c_{1} + 14c_{2}\end{bmatrix} = \begin{bmatrix}5\\2\end{bmatrix}
            </me>,
            so <m>c_{2} = \frac{5}{3}</m> and <m>c_{1} = 2 - 14\frac{5}{3} = -\frac{64}{3}</m>.
          </p>

          <p>
            So the solution of the matrix ODE (and hence the original system) is
            <me>
              \vec{x} = \begin{bmatrix}5e^{-\frac{t}{2}} \\ -\frac{64}{3}e^{-\frac{5t}{7}}+\frac{70}{3}e^{-\frac{t}{2}}\end{bmatrix}
            </me>.
            The amount of salt in the first tank, <m>x_{1}</m>, is given by the top entry and the amount of salt in the second tank, <m>x_{2}</m>, is given by the bottom entry.
          </p>
        </solution>
      </example>
    </subsection>
  </section>

  <section xml:id="section-phase-plane-criteria-for-critical-points-stability">
    <title>Phase portraits and critical points</title>

    <introduction>
      <p>
        The techniques used in <xref ref="section-population-models-and-autonomous-equations" text="type-global" /> to study long-term behavior of solutions near critical points can be adapted to higher dimensional systems as well.
        The main difference now is that we must consider the <em>phase plane</em> instead of a simple one-dimensional number line.
        This also allows for different types of behavior at critical points for solutions, or <em>trajectories</em>, near the critical point.
      </p>
    </introduction>


    <subsection xml:id="subsection-the-phase-plane">
      <title>The phase plane</title>

      <p>
        Just as we were able to plot direction fields for first-order autonomous ODEs, we can do something similar for autonomous first-order systems with two equations and constant coefficients.
        These are precisely the systems that can be written as a matrix ODE of the form
        <me>
          \vec{x}^\prime = A\vec{x}
        </me>
        where <m>A</m> is a <m>2\times2</m> matrix.
      </p>

      <p>
        Consider the first-order system
        <mdn>
          <mrow xml:id="equation-2-by-2-system">x^\prime_{1}  \amp =  a_{11}x_{1} + a_{12}x_{2}</mrow>
          <mrow number="no">x^\prime_{2}  \amp =  a_{21}x_{1}+  a_{22}x_{2}</mrow>
        </mdn>
        or
        <me>
          \vec{x}^\prime = A\vec{x}\quad\text{where}\quad A = \begin{bmatrix}a_{11}  \amp  a_{12}  \\  a_{21}  \amp  a_{22}\end{bmatrix}
        </me>.
        The solution of this system looks like <m>\vec{x}(t) = \begin{bmatrix}x_{1}(t) \\ x_{2}(t)\end{bmatrix}</m>.
      </p>

      <p>
        As <m>t</m> varies, <m>\vec{x}(t)</m> will trace out a curve in the <m>x_{1}x_{2}</m>-plane, which we call a <term>trajectory</term>.
        The <m>x_{1}x_{2}</m>-plane is called the <term>phase plane</term>, and the collection of all trajectories of the system <xref ref="equation-2-by-2-system" text="type-global" /> is called the <term>phase portrait</term> of the system.
        The phase portrait of a system provides us with a way to study the behavior of solutions of <xref ref="equation-2-by-2-system" text="type-global" /> without actually solving the system.
      </p>

      <example xml:id="example-sketch-phase-portrait">
        <title>Sketching a phase portrait</title>

        <statement>
          <p>
            Sketch a phase portrait for the system
            <md>
              <mrow>\dv{y_{1}}{t}  \amp =  2y_{1} - 3y_{2}</mrow>
              <mrow>\dv{y_{2}}{t}  \amp =  -2y_{1} + y_{2}.</mrow>
            </md>
          </p>
        </statement>

        <solution>
          <p>
            First, note that we can rewrite the system as <m>\vec{y}^\prime = A\vec{y}</m> using
            <me>
              \vec{y} = \begin{bmatrix}y_{1}\\y_{2}\end{bmatrix}\quad\text{and}\quad A = \begin{bmatrix}2 \amp  -3 \\-2 \amp  1\end{bmatrix}
            </me>.
            Now, we can view <m>\vec{y}</m> as corresponding to a point in the phase plane.
            Hence <m>\vec{y}^\prime</m> corresponds to a <em>tangent</em> of a trajectory passing through the point <m>\vec{y}</m>.
          </p>

          <p>
            For example, let's find the tangent at the point <m>\vec{y} = \begin{bmatrix}2\\2\end{bmatrix}</m>.
            The tangent is given by the corresponding <m>\vec{y}^\prime</m> at this point which is just <m>A\vec{y}</m>:
            <me>
              \vec{y}^\prime = A\vec{y} = \begin{bmatrix}2 \amp  -3 \\ -2 \amp  1\end{bmatrix}\begin{bmatrix}2\\2\end{bmatrix} = \begin{bmatrix}-2 \\ -2\end{bmatrix}
            </me>.
            So at the point <m>(2,2)</m> in the phase plane, the trajectory should be heading in the same direction as that of the point <m>(-2,-2)</m> relative to the origin.
            In other words, the tangent vector would point two units left and two units down from the point <m>(2,2)</m>.
          </p>

          <p>
            Similarly, if we let <m>\vec{y} = \begin{bmatrix}0\\1\end{bmatrix}</m> then we get
            <me>
              \vec{y}^\prime = A\vec{y} = \begin{bmatrix}2 \amp  -3 \\ -2 \amp  1\end{bmatrix}\begin{bmatrix}0\\1\end{bmatrix} = \begin{bmatrix}-3 \\ 1\end{bmatrix}
            </me>.
            So the trajectory going through <m>(0,1)</m> in the phase plane should be heading in the direction of <m>(-3,1)</m> viewed from the origin.
            Plotting other points in the phase plane like this, we get the image below.
          </p>

          <image xml:id="image-sketch-phase-portrait" width="50%">
            <asymptote>
              import graph;
              import fontsize;
              size(200);
              defaultpen(fontsize(9pt));
              pair a=(-2,-2);
              pair b=(2,2);
              real xmin=-2, xmax=2;
              real ymin=-2, ymax=2;
              real eps=.2;
              //incoming and outgoing trajectories
              real f_in(real x) {return x;}
              real f_out(real x) {return -(2/3)*x;}
              //nullclines
              real y1(real x) {return (2/3)*x;}
              real y2(real x) {return 2*x;}
              //plot annotations
              arrowbar axisarrow = Arrow(TeXHead);
              Label xlabel = Label("$y_1$", position = EndPoint, align = 2E);
              Label ylabel = Label("$y_2$", position = EndPoint, align = 2N);
              path vector(pair z) {return (0,0) -- unit((2z.x - 3z.y,-2z.x + z.y));}
              //graph phase portrait, trajectories and nullclines
              add(vectorfield(vector,a,b,15,deepcyan+0.2bp));
              draw(graph(f_in,xmin,xmax),blue);
              draw(graph(f_out,xmin-eps,xmax+eps),red);
              draw(graph(y1,xmin,xmax),deepmagenta);
              draw(graph(y2,xmin/2,xmax/2),deepmagenta);
              //draw labels
              label(rotate(45)*Label("$y_2=y_1$"), (1, f_in(1)), SE, blue);
              label(rotate(-atan(2/3)*(180/pi))*"$y_2=-\frac{2}{3}y_1$", (1, f_out(1)), NE, red);
              label(rotate(atan(2/3)*(180/pi))*"$\dot{y_1}=0$", (.5, y1(.5)), SE, deepmagenta);
              label(rotate(atan(2)*(180/pi))*"$\dot{y_2}=0$", (.55, y2(.55)), SE, deepmagenta);
              //label axes and origin
              xaxis(YZero,xmin-eps,xmax+eps, LeftTicks(NoZeroFormat), L=xlabel, arrow=axisarrow);
              yaxis(XZero,ymin-eps,ymax+eps, RightTicks(NoZeroFormat), L=ylabel, arrow=axisarrow);
              label("$0$", (0,0), SE);
            </asymptote>
          </image>

          <p>
            One thing we can see from this is that trajectories that lie on the line <m>y_1 = y_2</m>, which corresponds to the initial conditions <m>y_{1}(0) = y_{2}(0)</m>, appear to approach the origin while all others move away from the origin.
            Likewise, the trajectories on the line <m>y_2 = -\frac{2}{3}y_1</m> move directly away from the origin.
            We can see why this is by looking at the general solution of the original system, which is
            <me>
              \vec{y} = c_{1}e^{4t}\begin{bmatrix}-3\\2\end{bmatrix}+c_{2}e^{-t}\begin{bmatrix}1\\1\end{bmatrix}
            </me>.
          </p>

          <p>
            If <m>\vec{y}</m> lies on the line <m>y_{2} = y_{1}</m>, then <m>c_{1}</m> has to equal <m>0</m>, which follows from the fact that <m>\begin{bmatrix}-3\\2\end{bmatrix}</m> and <m>\begin{bmatrix}1\\1\end{bmatrix}</m> are linearly independent.
            So trajectories that lie on the line <m>y_{2} = y_{1}</m> must take the form <m>\vec{y} = c_{2}e^{-t}\begin{bmatrix}1\\1\end{bmatrix}</m>, and every solution of this form goes to <m>\vec{0}</m> as <m>t\to\infty</m>.
            <em>Every other trajectory</em> will move away from the origin as <m>t\to\infty</m>, although the trajectories that lie on the line <m>y_{2} = -\frac{2}{3}y_{1}</m> will travel to the origin as <m>t\to-\infty</m> (i.e.
            <q>backwards in time</q>):
          </p>
        </solution>
      </example>

      <p>
        Vector fields can also be plotted easily using SageMath.
        The code cell below demonstrates the use of the <c>plot_vector_field</c> command to sketch the phase portrait from <xref ref="example-sketch-phase-portrait" text="type-global" />.
      </p>
      <sage>
      <input>
          # Define variables
          var('y1 y2')
          # Create phase portrait for system
          VF=plot_vector_field([2*y1 - 3*y2,-2*y1 + y2],[y1,-2,2],[y2,-2,2])
          # Display the plot
          show(VF)
      </input>
      </sage>

      <p>
        Note that <m>\vec{x}=\vec{0}</m> is <em>always</em> a solution of <m>\vec{x}^\prime=A\vec{x}</m>.
        This is because <m>\vec{0}^\prime=A\vec{0} = \vec{0}</m>.
        We call <m>\vec{x} = \vec{0}</m> the <term>equilibrium solution</term> or <term>critical point</term> of the system <m>\vec{x}^\prime=A\vec{x}</m>.
        Later in this section, we will be concerned with the behavior of trajectories of the system <m>\vec{x}^\prime=A\vec{x}</m> near the equilibrium solution <m>\vec{x}=\vec{0}</m>.
        One thing we will see is that the behavior is determined in large part by the eigenvalues of the matrix <m>A</m>.
      </p>

      <p>
        We will separate the behavior of trajectories at the critical point <m>\vec{x} = \vec{0}</m> into five different cases:
      </p>

      <table xml:id="table-systems-ode-critical-point-types">
        <title>Types of critical points</title>

        <tabular top="major">
          <row bottom="major">
            <cell>Classification</cell>
            <cell>Behavior at <m>\vec{0}</m></cell>
          </row>

          <row>
            <cell>Improper node</cell>
            <cell>Every trajectory except two has the same limiting tangent at <m>\vec{0}</m></cell>
          </row>

          <row>
            <cell>Proper node</cell>
            <cell>For every direction <m>\vec{d}</m> there exists trajectory with limiting tangent <m>\vec{d}</m></cell>
          </row>

          <row>
            <cell>Saddle point</cell>
            <cell>Two incoming trajectories, two outgoing trajectories; all others bypass <m>\vec{0}</m></cell>
          </row>

          <row>
            <cell>Center</cell>
            <cell><m>\vec{0}</m> is enclosed by infinitely many closed (repeating) trajectories</cell>
          </row>

          <row bottom="major">
            <cell>Spiral point</cell>
            <cell>Trajectories spiral inwards or outwards from <m>\vec{0}</m></cell>
          </row>
        </tabular>
      </table>

      <p>
        <m>\vec{0}</m> was a saddle point in <xref ref="example-sketch-phase-portrait" text="type-global" /> since there were incoming trajectories on the line <m>y_{2} = y_{1}</m> and outgoing trajectories on the line <m>y_{2} = -\frac{2}{3}y_{1}</m> as indicated in <xref ref="figure-sketch-phase-portrait" text="type-global" />.
      </p>

      <example xml:id="example-stability-equilibrium-solution">
        <title>Classifying a critical point using a phase portrait</title>

        <statement>
          <p>
            Using a phase portrait, determine the type of critical point that <m>\vec{y} = \vec{0}</m> is for the matrix ODE <m>\vec{y}^\prime=A\vec{y}</m> where
            <me>
              \vec{y} = \begin{bmatrix}y_{1}(t) \\ y_{2}(t)\end{bmatrix}\quad\text{and}\quad A = \begin{bmatrix}3 \amp  4 \\ -4 \amp  3\end{bmatrix}
            </me>.
          </p>
        </statement>

        <solution>
          <p>
            This system produces the following phase portrait:
          </p>

          <image xml:id="image-classify-stability-using-phase-portrait" width="50%">
            <asymptote>
                import graph;
                import fontsize;
                size(200);
                defaultpen(fontsize(9pt));
                pair a=(-2,-2);
                pair b=(2,2);
                real xmin=-2, xmax=2;
                real ymin=-2, ymax=2;
                real eps=.2;
                //plot annotations
                arrowbar axisarrow = Arrow(TeXHead);
                Label xlabel = Label("$y_1$", position = EndPoint, align = 2E);
                Label ylabel = Label("$y_2$", position = EndPoint, align = 2N);
                path vector(pair z) {return (0,0) -- unit((3z.x + 4z.y,-4z.x + 3z.y));}
                add(vectorfield(vector,a,b,15,deepcyan+0.2bp));
                //label axes
                xaxis(YZero,xmin-eps,xmax+eps, LeftTicks(NoZeroFormat), L=xlabel, arrow=axisarrow);
                yaxis(XZero,ymin-eps,ymax+eps, RightTicks(NoZeroFormat), L=ylabel, arrow=axisarrow);
                label("$0$", (0,0), SE);
            </asymptote>
          </image>

          <p>
            As seen above, every (nonzero) trajectory will spiral outward from <m>\vec{y} = \vec{0}</m> as <m>t\to\infty</m>, so <m>\vec{0}</m> is a spiral point of this system.
            To see why, we only need to look at the eigenvalues of <m>A</m>, which we find to be
            <me>
              \lambda_{1} = 3+4i,\lambda_{2} = 3-4i
            </me>.
            This means that the general solution of <m>\vec{y}^\prime = A\vec{y}</m> must look like
            <md>
              <mrow>\vec{y} \amp = c_{1}e^{(3+4i)t}\vec{y}_{1} + c_{2}e^{(3-4i)t}\vec{y}_{2}</mrow>
              <mrow>\amp = e^{3t}\brackets{c_{1}e^{4it}\vec{y}_{1}+c_{2}e^{-4it}\vec{y}_{2}}</mrow>
              <mrow>\amp = e^{3t}\brackets{(\cos4t)\vec{x}_{1}+(\sin4t)\vec{x}_{2}}</mrow>
            </md>.
          </p>

          <p>
            The real part of the eigenvalues leads to the <q>growth term</q> of <m>e^{3t}</m> appearing in the solution, which causes the trajectories to diverge as <m>t\to\infty</m>.
            The imaginary part of the eigenvalues leads to the <q>oscillating terms</q> of <m>\cos4t,\sin4t</m> appearing in the solution, which gives the trajectories their spiral motion.
          </p>
        </solution>
      </example>

      <p>
        In general, the eigenvalues of the matrix <m>A</m> in the system <m>\vec{y}^\prime = A\vec{y}</m> will determine the type of critical point that <m>\vec{0}</m> is for the system <m>\vec{y}^\prime=A\vec{y}</m>.
      </p>

      <example xml:id="example-systems-odes-classifying-trajectories-algebraically">
        <title>Classifying trajectories algebraically</title>

        <statement>
          <p>
            What kind of critical point is <m>\vec{y} = \vec{0}</m> for the system
            <md>
              <mrow>y^\prime_{1} \amp = -4y_{2}</mrow>
              <mrow>y^\prime_{2}  \amp =  4y_{1}</mrow>
            </md>
            where <m>y_{i} = y_{i}(t)</m>?
          </p>
        </statement>

        <solution>
          <p>
            We could sketch the phase portrait for this system, but we can also determine the behavior of the trajectories <m>\vec{y} = \begin{bmatrix} y_{1} \\ y_{2} \end{bmatrix} </m> if we can find a relationship between <m>y_{1}</m> and <m>y_{2}</m>.
            To do so, we <q>cross-multiply</q> the system to get
            <me>
              4y_{1}y^\prime_{1} = -4y_{2}y^\prime_{2} \quad\text{or}\quad 4y_{1}\dd{y_{1}} = -4y_{2}\dd{y_{2}}
            </me>.
            So we can integrate this to get
            <me>
              2y_{1}^{2} = -2y_{2}^{2}+C\qq{or}y_{1}^{2}+y_{2}^{2} = C_{1}
            </me>.
          </p>

          <p>
            This is the equation of a circle of radius <m>\sqrt{C_{1}}</m>, and so every trajectory <m>\vec{y}</m> for this system will be a circle centered at <m>\vec{0}</m>.
            Hence <m>\vec{0}</m> is a center.
          </p>
        </solution>
      </example>
    </subsection>


    <subsection xml:id="subsection-eigenvalue-criteria-for-stability">
      <title>Eigenvalue criteria for stability</title>

      <p>
        Consider the matrix ODE <m>\vec{y}^\prime = A\vec{y}</m>.
        Let <m>\lambda_{1},\lambda_{2}</m> denote the eigenvalues of the <m>2\times 2</m> matrix <m>A</m>.
        Then we can classify <m>\vec{0}</m> using <xref ref="table-eigenvalue-conditions-stability"/>.
      </p>

      <table xml:id="table-eigenvalue-conditions-stability">
        <title>Eigenvalue conditions for stability</title>

        <tabular top="major">
          <row bottom="major">
            <cell>Name</cell>
            <cell>Conditions on <m>\lambda_{1},\lambda_{2}</m></cell>
          </row>

          <row>
            <cell>Node</cell>
            <cell>Real, same sign</cell>
          </row>

          <row>
            <cell>Saddle point</cell>
            <cell>Real, opposite sign</cell>
          </row>

          <row>
            <cell>Center</cell>
            <cell>Pure imaginary</cell>
          </row>

          <row bottom="major">
            <cell>Spiral point</cell>
            <cell>Complex, not pure imaginary</cell>
          </row>
        </tabular>
      </table>
      <aside>
      <p>
        The rule of thumb is this: the real parts of the eigenvalues determine whether a trajectory moves towards or away from the origin, and the imaginary part determines if the trajectory has a periodic/oscillating nature to it.
      </p>
      </aside>

      <p>
        We say that the origin is a <term>stable</term> critical point of <m>\vec{y}^\prime=A\vec{y}</m> if all trajectories that start <q>close</q> to <m>\vec{0}</m> remain close at all future times.
        Equivalently, it's stable if each trajectory will eventually be contained within some circle centered at the origin as <m>t\to\infty</m>.
        Otherwise, we say that <m>\vec{0}</m> is <term>unstable</term>.
        If it so happens that every trajectory that starts close to <m>\vec{0}</m> tends to <m>\vec{0}</m> as <m>t\to\infty</m>, we then say that <m>\vec{0}</m> is a <term>stable and attractive</term> (or <term>asymptotically stable</term>) critical point.
        Equivalently, <m>\vec{0}</m> is asymptotically stable if <em>every</em> trajectory goes to <m>\vec{0}</m> as <m>t\to\infty</m>.
      </p>

      <example xml:id="example-systems-odes-eigenvalue-conditions-for-asymptotically-stable-critical-points">
        <title>Eigenvalue conditions for asymptotic stability</title>

        <statement>
          <p>
            Let <m>\vec{y}^\prime = A\vec{y}</m> denote a matrix ODE where <m>A</m> is a constant <m>2\times2</m> matrix.
            What conditions on the eigenvalues of <m>A</m> will give an asymptotically stable critical point at <m>\vec{y}=\vec{0}</m>?
          </p>
        </statement>

        <solution>
          <p>
            Let <m>\vec{y} = \vec{y}(t)</m> denote a nonzero solution of the matrix ODE (and therefore a trajectory).
            Then in order for <m>\vec{0}</m> to be asymptotically stable, we need <m>\vec{y}\to\vec{0}</m> as <m>t\to\infty</m>.
            Let <m>\lambda_{1},\lambda_{2}</m> denote the eigenvalues of <m>A</m>.
            Then <m>\vec{y}</m> will have the form
            <me>
              \vec{y} = c_{1}e^{\lambda_{1}t}\vec{y}_{1}+c_{2}e^{\lambda_{2}t}\vec{y}_{2}
            </me>.
          </p>

          <p>
            The previous paragraph shows that <m>\vec{y}</m> must go to <m>\vec{0}</m> as <m>t\to\infty</m> if either <m>c_{1}=c_{2}=0</m> or if each exponential goes to <m>0</m> as <m>t\to\infty</m>.
            Since we assume <m>\vec{y}\neq\vec{0}</m>, this means we need <m>e^{\lambda_{i}t}\to0</m> for <m>i=1,2</m> as <m>t\to\infty</m>.
            This implies that the <em>real part</em> of each eigenvalue must be negative, because the real part of each eigenvalue is what determines the growth of <m>e^{\lambda_{i}t}</m>: if <m>\lambda_{i} = a+bi</m>, then
            <me>
              e^{\lambda_{i}t} = e^{at}[A\cos bt+B\sin bt]
            </me>.
            So <m>\vec{0}</m> is asymptotically stable if the real parts of <em>both</em> eigenvalues are negative.
          </p>
        </solution>
      </example>

      <p>
        By a similar argument to that used in <xref ref="example-systems-odes-eigenvalue-conditions-for-asymptotically-stable-critical-points" text="type-global" />, we can say that <m>\vec{0}</m> is stable as long as the real part of each eigenvalue is no greater than <m>0</m>.
        Likewise, <m>\vec{0}</m> is unstable if the real part of <em>any</em> eigenvalue is positive.
      </p>

      <example xml:id="example-systems-odes-critical-point-tank-system">
        <title>Long term behavior of a system of interconnected tanks</title>

        <statement>
          <p>
            Two tanks <m>T_{1}</m> and <m>T_{2}</m> containing <quantity> <mag>200</mag> <unit base="gallon" /> </quantity> each of a water-salt mixture are set up as follows:
            <ul>
              <li>
                <p>
                  Tank 1: Pure water flows in at <quantity> <mag>12</mag> <unit base="gallon" /> <per base="minute" /> </quantity> and solution from Tank 2 flows in at <quantity> <mag>4</mag> <unit base="gallon" /> <per base="minute" /> </quantity>; solution also flows out of Tank 1 and into Tank 2 at <quantity> <mag>16</mag> <unit base="gallon" /> <per base="minute" /> </quantity>.
                </p>
              </li>

              <li>
                <p>
                  Solution from Tank 1 flows in at <quantity> <mag>16</mag> <unit base="gallon"/> <per base="minute"/> </quantity>; solution flows out of Tank 2 and into Tank 1 at <quantity> <mag>4</mag> <unit base="gallon"/> <per base="minute"/> </quantity>, and solution is emptied from Tank 2 at an addition rate of <quantity> <mag>12</mag> <unit base="gallon"/> <per base="minute"/> </quantity>
                </p>
              </li>
            </ul>
            Will the salt eventually empty from both tanks?
          </p>
        </statement>

        <solution>
          <p>
            Let <m>y_{1}(t)</m> denote the amount of salt (in pounds) in Tank 1 at time <m>t</m> (in minutes), and let <m>y_{2}(t)</m> do the same for Tank 2.
            Then
            <md>
              <mrow>y^\prime_{1}  \amp =  4\frac{y_{2}}{200} - 16\frac{y_{1}}{200}</mrow>
              <mrow>y^\prime_{2}  \amp =  16\frac{y_{1}}{200} - 16\frac{y_{2}}{200}</mrow>
            </md>.
            This system is equivalent to the matrix ODE <m>\vec{y}^\prime = A\vec{y}</m> where
            <me>
              \vec{y} = \begin{bmatrix}y_{1}\\y_{2}\end{bmatrix}\quad\text{and}\quad A = \begin{bmatrix}-\frac{2}{25} \amp  \frac{1}{50} \\ \frac{2}{25} \amp  -\frac{2}{25}\end{bmatrix}
            </me>.
            We need to determine the long-term behavior of solutions of this ODE, which is itself determined by the eigenvalues of <m>A</m>.
          </p>

          <p>
            The eigenvalues of <m>A</m> are
            <me>
              \lambda_{1} = -\frac{1}{25}\quad\text{and}\quad\lambda_{2} = -\frac{3}{25}
            </me>.
            Since both eigenvalues have negative real part, it follows that <m>\vec{0}</m> is an asymptotically stable critical point of <m>\vec{y}^\prime=A\vec{y}</m>.
            Therefore <em>every</em> trajectory <m>\vec{y}\to\vec{0}</m> as <m>t\to\infty</m>.
            So no matter how much salt is initially in the tanks, the amount of salt will always go to <m>0</m>.
          </p>
        </solution>
      </example>
    </subsection>
  </section>

  <section xml:id="section-nonlinear-systems">
    <title>Nonlinear systems</title>

    <introduction>
      <p>
        Now we apply phase plane methods to study <term>nonlinear autonomous systems</term>, which for systems involving two ODEs take the form
        <md>
          <mrow>y^\prime_{1} \amp = f_{1}(y_{1},y_{2})</mrow>
          <mrow>y^\prime_{2} \amp = f_{2}(y_{1},y_{2})</mrow>
        </md>.
        where <m>y_{i} = y_{i}(t)</m>.
      </p>
      <aside>
      <p>
        <em>Autonomous</em> just means we can write the system without explicitly referring to the independent variable <m>t</m>.
      </p>
      </aside>

      <p>
        We can also write such a system as a vector equation:
        <men xml:id="equation-nonlinear-system">
          \vec{y}^\prime = \vec{f}(\vec{y})
        </men>.
        although not as a matrix ODE (if the functions <m>f_{i}</m> are nonlinear).
      </p>

      <p>
        Just as in the previous sections, the <term>phase plane</term> is still the <m>y_{1}y_{2}</m>-plane, <term>trajectories</term> are still the solutions <m>\vec{y}</m> of <xref ref="equation-nonlinear-system" text="type-global" /> (represented as curves in the phase plane), and the <term>phase portrait</term> of <xref ref="equation-nonlinear-system" text="type-global" /> is the set of all trajectories in the phase plane.
      </p>

      <p>
        We call a point <m>P = (y_1, y_2)</m> in the phase plane a <term>critical point</term> of <xref ref="equation-nonlinear-system" text="type-global" /> if
        <me>
          f_{1}(y_{1},y_{2}) = 0\quad\text{and}\quad f_{2}(y_{1},y_{2}) = 0
        </me>.
        In other words, <m>P</m> is a critical point of <m>\vec{y}^\prime = \vec{f}(\vec{y})</m> if <m>\vec{f}(P) = \vec{0}</m>.
        Just as before, critical points represent solutions of the system that are in equilibrium.
      </p>

      <example xml:id="example-systems-odes-pendulum-system">
        <title>The pendulum equation</title>

        <statement>
          <p>
            Express the <em>pendulum equation</em> <m>\theta''+\frac{g}{l}\sin\theta=0</m>, where <m>\theta=\theta(t)</m> represents the angular displacement of a pendulum from the vertical, as a nonlinear system <m>\vecm{\theta}^\prime = \vec{f}(\vecm{\theta})</m> and then find its critical points.
          </p>
        </statement>

        <solution>
          <p>
            First, we have to rewrite the pendulum ODE as a first order system.
            We can do this without too much trouble as follows: set
            <me>
              \theta_{1} = \theta\quad\text{and}\quad\theta_{2} = \theta_{1}^\prime = \theta^\prime
            </me>.
            Then the ODE <m>\theta''+\frac{g}{l}\sin\theta = 0</m> turns into the system
            <md>
              <mrow>\theta^\prime_{1} \amp = \theta_{2}</mrow>
              <mrow>\theta^\prime_{2} \amp = -\frac{g}{l}\sin\theta_{1}</mrow>
            </md>,
            which we can also write as <m>\boldsymbol{\theta}^\prime = \vec{f}(\boldsymbol{\theta})</m> using
            <me>
              \vecm{\theta} = \begin{bmatrix}\theta_{1} \\ \theta_{2}\end{bmatrix}\quad\text{and}\quad \vec{f}(\vecm{\theta}) = \begin{bmatrix}\theta_{2} \\ -\frac{g}{l}\sin\theta_{2}\end{bmatrix}
            </me>.
          </p>

          <p>
            Now we need to find the critical points <m>\vecm{\theta}</m> in the <m>\theta_{1}\theta_{2}</m>-plane that make <m>\vec{f}(\vecm{\theta}) = \vec{0}</m>.
            This requires <m>\theta_{2} = 0</m> and <m>\theta_{1} = \pm k\pi</m> for <m>k=0,\pm1,\pm2,\dots</m>, and so the critical points of this system are all points of the form <m>(\pm k\pi,0)</m>.
          </p>
        </solution>
      </example>
    </introduction>


    <subsection xml:id="subsection-classification-of-critical-points-and-linearization">
      <title>Classification of critical points and linearization</title>

      <p>
        Critical points of systems are important because they can represent long-term behavior of a system.
        For example, if we have a first-order system representing the population of two species, and it turns out the the origin is asymptotically stable, then this suggests that both species could be driven to extinction.
        So we want to classify critical points for nonlinear systems in addition to what we have already for linear systems; unfortunately, nonlinear systems are often difficult, if not outright impossible, to solve exactly.
      </p>

      <p>
        Thankfully, in many cases we can approximate a nonlinear system <m>\vec{y}^\prime = \vec{f}(\vec{y})</m> with critical points <m>P_{i}</m> by a suitably chosen linear system <m>\vec{y}^\prime = A\vec{y}</m> at each critical point <m>P_{i}</m>; we call such a system the <term>linearization</term> at <m>P_{i}</m>.
      </p>

      <definition xml:id="definition-the-jacobian-of-a-nonlinear-system">
        <title>The Jacobian of a nonlinear system</title>

        <idx>Jacobian</idx>
        <notation>
          <usage> <m>J_{\vec{f}}(\vec{y})</m> </usage>
          <description>
            Jacobian of <m>\vec{y}^\prime = \vec{f}(\vec{y})</m>
          </description>
        </notation>

        <statement>
          <p>
            Let
            <me>
              \vec{y} = \begin{bmatrix}y_{1} \\ y_{2}\end{bmatrix}\quad\text{and}\quad\vec{f}(\vec{y}) = \begin{bmatrix}f_{1}(y_{1},y_{2}) \\ f_{2}(y_{1},y_{2})\end{bmatrix}
            </me>.
            The <term>Jacobian</term> of <m>\vec{f}</m> is the matrix <m>J_{\vec{f}}(y_{1},y_{2})</m> given by
            <me>
              J_{\vec{f}}(y_{1},y_{2}) = \begin{bmatrix}\pdv{f_{1}}{y_{1}} \amp  \pdv{f_{1}}{y_{2}} \\ \pdv{f_{2}}{y_{1}} \amp  \pdv{f_{2}}{y_{2}}\end{bmatrix}
            </me>.
          </p>
          <aside>
          <p>
            If <m>\vec{f}</m> is understood from context, we often write <m>J</m> instead of <m>J_{\vec{f}}</m> for the Jacobian.
          </p>
          </aside>
        </statement>
      </definition>

      <p>
        The Jacobian is important since it allows us to <em>linearize</em> a nonlinear system.
        More precisely, the <term>linearization</term> of <m>\vec{y}^\prime = \vec{f}(\vec{y})</m> at the point <m>P = (p_{1},p_{2})</m> is the linear system <m>\vec{y}^\prime = A\vec{y}</m>, where
        <me>
          A = J(p_{1},p_{2}).
        </me>
      </p>

      <example xml:id="example-systems-odes-linearize-pendulum-system">
        <title>Linearizing the pendulum system</title>

        <statement>
          <p>
            Find the linearization of the pendulum system <m>\vecm{\theta}^\prime = \vec{f}(\vecm{\theta})</m> at the critical point <m>(0,0)</m>.
          </p>
        </statement>

        <solution>
          <p>
            For this system, we have <m>f_{1}(\theta_{1},\theta_{2}) = \theta_{2}</m> and <m>f_{2}(\theta_{1},\theta_{2}) = -\frac{g}{l}\sin\theta_{1}</m>.
            The Jacobian is then given by
            <me>
              J(\theta_{1},\theta_{2}) = \begin{bmatrix}0 \amp  1 \\ -\frac{g}{l}\cos\theta_{1} \amp  0\end{bmatrix}
            </me>.
            So to get the linearization we need to set
            <me>
              A = J(0,0) = \begin{bmatrix}0 \amp  1 \\ -\frac{g}{l} \amp  0\end{bmatrix}
            </me>.
          </p>
        </solution>
      </example>

      <p>
        The linearization of a nonlinear system isn't just useful for approximating the nonlinear system.
        It's also incredibly useful for classifying the critical points of a nonlinear system; for the most part, the eigenvalues of the matrix <m>A</m> from the linearization also classify the critical points of the system <m>\vec{y}^\prime = \vec{f}(\vec{y})</m>.
      </p>

      <example xml:id="example-systems-odes-classify-critical-points-linearization">
        <title>Classifying critical points using linearization</title>

        <statement>
          <p>
            Find and classify the critical points of the nonlinear system
            <md>
              <mrow>\dv{x}{t} \amp = x - y - x^{2} + xy </mrow>
              <mrow>\dv{y}{t} \amp = -x^{2} - y </mrow>
            </md>.
          </p>
          <aside>
          <p>
            This example taken from <url href="https://www.math.uci.edu/~ndonalds/math3d/nonlinear.pdf" visual="www.math.uci.edu/~ndonalds/math3d/nonlinear.pdf">here.</url>
          </p>
          </aside>
        </statement>

        <solution>
          <p>
            The critical points occur at intersections between the nullclines <m>\dot{x}=0</m> and <m>\dot{y}=0</m>.
            The equations of the nullclines for <m>\dot{x}=0</m> are
            <md>
              <mrow>x \amp = 1 </mrow>
              <mrow>y \amp = x </mrow>
            </md>,
            while the equation of the nullcline <m>\dot{y}=0</m> is
            <me>
              y = -x^2
            </me>.
            Now we graph the nullclines (and the phase portrait):
          </p>

          <image xml:id="image-classify-critical-points" width="50%">
            <asymptote>
              import graph;
              import fontsize;
              size(200);
              defaultpen(fontsize(9pt));
              real eps=.1;
              real xmin=-2, xmax=2;
              real ymin=-2, ymax=2;
              pair a=(xmin,ymin);
              pair b=(xmax,ymax);
              //incoming and outgoing trajectories
              //real f_in(real x) {return x;}
              //real f_out(real x) {return -(2/3)*x;}
              //nullclines
              real xdot1(real x) {return x;}
              real ydot1(real x) {return -x^2;}
               //define and add curve
              pair xdot2(real y) {
                return (1, y);
              }
              path curveC = graph(xdot2, ymin, ymax, operator ..); // "operator .." is for bezier; 0t2
              Label Lx1 = Label("$\dot{x}=0$", deepmagenta, position=Relative(0.65), align=W);
              Label Lx2 = Label("$\dot{x}=0$", deepmagenta, position=Relative(0.6), align=E);
              Label Ly = Label("$\dot{y}=0$", deepblue, position=Relative(0.25), align=E);
              draw(graph(xdot1,xmin,xmax), deepmagenta, L=rotate(45)*Lx1);
              draw(graph(ydot1,xmin,xmax), deepblue, L=rotate(degrees(atan(2.2)))*Ly);
              draw(curveC, deepmagenta+0.6bp, L = rotate(-90)*Lx2);
              //plot annotations
              arrowbar axisarrow = Arrow(TeXHead);
              Label xlabel = Label("$x$", position = EndPoint, align = 2E);
              Label ylabel = Label("$y$", position = EndPoint, align = 2N);
              path vector(pair z) {return (0,0) -- ((z.x - z.y-z.x*z.x + z.x*z.y,-z.x^2 - z.y));}
              //graph phase portrait
              add(vectorfield(vector,a,b,20,deepcyan+0.2bp));
              //Crop picture
              limits((-2,-2),(2,2),Crop);
              //graph critical points
              dot((0, 0));
              dot((-1, -1));
              dot((1,-1));
              //label("$(1,-1)$", (-1,-1), SE);
              //label axes
              xaxis(YZero,xmin-eps,xmax+eps, LeftTicks(NoZeroFormat), L=xlabel, arrow=axisarrow);
              yaxis(XZero,ymin-eps,ymax+eps, RightTicks(NoZeroFormat), L=ylabel, arrow=axisarrow);
              label("$0$", (0,0), SE);
            </asymptote>
          </image>

          <p>
            The nullclines for <m>\dot{x}</m> and <m>\dot{y}</m> intersect in three places.
            Hence, there are three critical points for this system: <m>(0,0), (-1,-1)</m> and <m>(1,-1)</m>.
          </p>

          <p>
            To determine the behavior of solutions at these critical points, we'll find the Jacobian at each point.
            First, we have
            <me>
              J(x,y) = \begin{bmatrix} 1 - 2x + y \amp x - 1 \\ -2x \amp -1\end{bmatrix}
            </me>.
            At <m>(0,0)</m>, we get
            <me>
              J(0,0) = \begin{bmatrix} 1 \amp -1 \\ 0 \amp -1\end{bmatrix}
            </me>.
            The eigenvalues are <m>1</m> and <m>-1</m>, meaning that this critical point is a saddle point.
            This is illustrated in the phase portrait below.
          </p>

          <image xml:id="image-classify-critical-points-linearization-0-0" width="50%">
            <asymptote>
                import graph;
                import fontsize;
                size(200);
                defaultpen(fontsize(9pt));
                real eps=.05;
                real xmin=-.5, xmax=.5;
                real ymin=-.5, ymax=.5;
                pair a=(xmin,ymin);
                pair b=(xmax,ymax);
                //incoming and outgoing trajectories
                //real f_in(real x) {return x;}
                //real f_out(real x) {return -(2/3)*x;}
                //nullclines
                //real y1(real x) {return (2/3)*x;}
                //real y2(real x) {return 2*x;}
                path vector(pair z) {return (0,0) -- ((z.x - z.y-z.x*z.x + z.x*z.y,-z.x^2 +- z.y));}
                //graph phase portrait
                add(vectorfield(vector,a,b,20,deepcyan+0.2bp));
                //graph critical point
                dot((0, 0));
                label("$(0,0)$", (0,0), SE);
                //label axes
                xaxis("$x$",BottomTop,LeftTicks);
                yaxis("$y$",LeftRight,RightTicks(trailingzero));
            </asymptote>
          </image>

          <p>
            At <m>(-1,-1)</m> we get
            <me>
              J(-1,-1) = \begin{bmatrix}2 \amp -2 \\ 2 \amp -1\end{bmatrix}
            </me>
            which has eigenvalues <m>\lambda = \frac{1}{2}\pm\frac{1}{2}\sqrt{7}i</m>.
            Hence <m>(-1,-1)</m> should be a spiral point.
          </p>

          <image xml:id="image-classify-critical-points-linearization-neg1-neg1" width="50%">
            <asymptote>
                import graph;
                import fontsize;
                size(200);
                defaultpen(fontsize(9pt));
                real eps=.05;
                real xmin=-1.5, xmax=-.5;
                real ymin=-1.5, ymax=-.5;
                pair a=(xmin,ymin);
                pair b=(xmax,ymax);
                //incoming and outgoing trajectories
                //real f_in(real x) {return x;}
                //real f_out(real x) {return -(2/3)*x;}
                //nullclines
                //real y1(real x) {return (2/3)*x;}
                //real y2(real x) {return 2*x;}
                //plot annotations
                //arrowbar axisarrow = Arrow(TeXHead);
                //Label xlabel = Label("$x$", position = EndPoint, align = 2E);
                //Label ylabel = Label("$y$", position = EndPoint, align = 2N);
                path vector(pair z) {return (0,0) -- ((z.x - z.y-z.x*z.x + z.x*z.y,-z.x^2 +- z.y));}
                //graph phase portrait
                add(vectorfield(vector,a,b,20,deepcyan+0.2bp));
                //graph critical point
                dot((-1, -1));
                label("$(-1,-1)$", (-1,-1), SE);
                //label axes
                xaxis("$x$",BottomTop,LeftTicks);
                yaxis("$y$",LeftRight,RightTicks(trailingzero));
            </asymptote>
          </image>

          <p>
            Finally, at <m>(1,-1)</m> we get
            <me>
              J(1,-1) = \begin{bmatrix} -2 \amp 0 \\ -2 \amp -1\end{bmatrix}
            </me>,
            which has eigenvalues <m>-2,-1</m>.
            Hence <m>(1,-1)</m> is an asymptotically stable node.
          </p>

          <image xml:id="image-classify-critical-points-linearization-1-neg1" width="50%">
            <asymptote>
                import graph;
                import fontsize;
                size(200);
                defaultpen(fontsize(9pt));
                real eps=.05;
                real xmin=.5, xmax=1.5;
                real ymin=-1.5, ymax=-.5;
                pair a=(xmin,ymin);
                pair b=(xmax,ymax);
                //incoming and outgoing trajectories
                //real f_in(real x) {return x;}
                //real f_out(real x) {return -(2/3)*x;}
                //nullclines
                //real y1(real x) {return (2/3)*x;}
                //real y2(real x) {return 2*x;}
                //plot annotations
                //arrowbar axisarrow = Arrow(TeXHead);
                //Label xlabel = Label("$x$", position = EndPoint, align = 2E);
                //Label ylabel = Label("$y$", position = EndPoint, align = 2N);
                path vector(pair z) {return (0,0) -- ((z.x - z.y-z.x*z.x + z.x*z.y,-z.x^2 - z.y));}
                //graph phase portrait
                add(vectorfield(vector,a,b,20,deepcyan+0.2bp));
                //graph critical point
                dot((1, -1));
                label("$(1,-1)$", (1,-1), SE);
                //label axes
                xaxis("$x$",BottomTop,LeftTicks);
                yaxis("$y$",LeftRight,RightTicks(trailingzero));
            </asymptote>
          </image>
        </solution>
      </example>

      <p>
        Linearization works well to classify the behavior of systems at certain types of critical points.
        A critical point <m>P</m> of a system is <term>hyperbolic</term> if the Jacobian <m>J(P)</m> has eigenvalues with nonzero real part.
        Unfortunately, linearization is not guaranteed to give an accurate description of the behavior of non-hyperbolic critical points.
      </p>

      <example xml:id="example-systems-odes-lotka-volterra">
        <title>The Lotka-Volterra population model</title>

        <statement>
          <p>
            Predator-prey populations can be modeled using the <em>Lotka-Volterra model</em>.
            Let <m>y_{1}(t)</m> denote the population of a prey species at time <m>t</m> and let <m>y_{2}(t)</m> denote the population of a predator species at time <m>t</m>.
            Then the <term>Lotka-Volterra model</term> says that
            <md>
              <mrow>y^\prime_{1} \amp = ay_{1}-by_{1}y_{2}</mrow>
              <mrow>y^\prime_{2} \amp = ky_{1}y_{2} - ly_{2}</mrow>
            </md>,
            where <m>a,b,k,l>0</m>.
            Find and classify the critical points of this system.
          </p>
        </statement>

        <solution>
          <p>
            The critical points are the points <m>(y_{1},y_{2})</m> that satisfy the equations
            <me>
              ay_{1}-by_{1}y_{2} = 0\quad\text{and}\quad ky_{1}y_{2} - ly_{2} = 0.
            </me>
            Equivalently, we need
            <me>
              y_{1}(a-by_{2}) = 0\quad\text{and}\quad y_{2}(ky_{1}-l) = 0.
            </me>
            This has solutions <m>y_{1} = y_{2} = 0</m> and <m>y_{1} = \frac{l}{k},y_{2} = \frac{a}{b}</m>, which shows that the critical points are <m>(0,0)</m> and <m>(\frac{l}{k},\frac{a}{b})</m>.
          </p>

          <p>
            To classify the critical points of this system we will linearize the system.
            The Jacobian of
            <me>
              \vec{f}(\vec{y}) = \begin{bmatrix}ay_{1}-by_{1}y_{2} \\ ky_{1}y_{2} - ly_{2}\end{bmatrix}
            </me>
            is
            <me>
              J(y_{1},y_{2}) = \begin{bmatrix}a-by_{2} \amp  -by_{1} \\ ky_{2} \amp  ky_{1} - l\end{bmatrix}
            </me>.
            Now we will examine the Jacobian at each critical point.
          </p>

          <p>
            At <m>(0,0)</m>, we get
            <me>
              J(0,0) = \begin{bmatrix}a \amp  0 \\ 0 \amp  -l\end{bmatrix}
            </me>,
            which has eigenvalues <m>\lambda=a,-l</m> which indicate a saddle point.
            Since these eigenvalues have nonzero real part, the origin is a hyperbolic critical point of the system and so we know that it also behaves as a saddle point in the original system.
            In particular, there exist trajectories heading into the origin, so it's possible for both species to go extinct in this model.
          </p>

          <p>
            Now we'll classify the second critical point <m>(\frac{l}{k},\frac{a}{b})</m>.
            The Jacobian at this point gives us the matrix
            <me>
              A = J(\frac{l}{k},\frac{a}{b}) = \begin{bmatrix}0 \amp  -\frac{bl}{k} \\ \frac{ak}{b} \amp  0\end{bmatrix}
            </me>.
            This matrix has characteristic equation <m>\lambda^{2} + al = 0</m>, and so has eigenvalues <m>\lambda=\pm i\sqrt{al}</m>.
            Since the eigenvalues are pure imaginary, this suggests that <m>(\frac{l}{k},\frac{a}{b})</m> is a center, which is indeed the case.
            In particular, trajectories near this critical point <em>must be periodic</em>.
            Unfortunately we can't quite justify this conclusion.
            This is because both eigenvalues of the Jacobian at this critical point have zero real part, which means that this critical point is not hyperbolic and so the behavior of the linearization is not guaranteed to match the behavior of the original system at this critical point.
            That said, a more detailed analysis (or simply a sketch of the phase portrait) does indeed confirm that <m>(\frac{l}{k}, \frac{a}{b})</m> is a center of the original system.
          </p>
        </solution>
      </example>
    </subsection>
  </section>

  <section xml:id="sec-sage-and-octave-for-systems-of-odes">
    <title>Sage and Octave for systems of ODEs</title>
    <introduction>
      <p>
        The purpose of this section is to discuss useful code in both Sage and Octave for working with systems of ODEs.
        Generally, algebraic work is best handled with Sage while numerical computations might be easier in Octave.
        Octave is designed as an open-source alternative to MATLAB, so familiarity with one programming language leads to familiarity with the other.
      </p>
    </introduction>
    <subsection xml:id="subsec-vectors-and-matrices">
      <title>Vectors and matrices</title>
      <p>
        The fundamental objects in this chapter are vectors and matrices.
        Both Sage and Octave are designed to handle these quantities, though Octave is better suited to dealing with purely numerical examples.
        In Sage, we can create vectors using the <c>vector</c> command, which takes as input a list of (possibly symbolic) values.
      </p>
      <sage>
        <input>
          v1 = vector([1, 2])
          v2 = vector([2*x, -3])
          v1 - v2
        </input>
        <output>
          (-2*x + 1, 5)
        </output>
      </sage>
      <p>
        You should note that the output produced by the <c>vector</c> command in Sage is not considered to be either a row vector or a column vector.
        If you specifically want to represent a row or column vector, you can use the <c>Matrix</c> command which we will see soon or the <c>row()</c> and <c>column()</c> methods:
      </p>
      <sage>
        <input>
          v1 = vector([1, 2])
          v1_col = v1.column()
          v1_row = v1.row()
          v1_col, v1_row
        </input>
        <output>
          (
          [1]       
          [2], [1 2]
          )
        </output>
      </sage>
      <p>
        In Octave, we can simply use brackets <c>[]</c> to define vectors (and matrices).
        Entries of a row vector must be separated by commas or spaces, while entries of a column vector must be separated by semicolons.
      </p>
      <sage language="octave">
        <input>
          v1_row = [1, 2]
          v1_col = [1; 2]
        </input>
        <output>
          v1_row =

          1 2

          v1_col =

          1
          2
        </output>
      </sage>
    </subsection>
  </section>
</chapter>
